---
title: "Resampling methods: Bootstrap and Permutation tests"
author: "Julia Wrobel"
format:
  beamer:
    theme: metropolis
    aspectratio: 169
    fontsize: 14pt
    slide-level: 2
execute:
  echo: true
  eval: true
  warning: false
  message: false
header-includes:
  - \usepackage{xcolor}
  - \newcommand{\red}[1]{\textcolor{red}{#1}}
  - \newcommand{\green}[1]{\textcolor{green}{#1}}
---

## Overview

```{r}
library(tidyverse)
```

Today, we cover:

- Resampling methods
  - Bootstrap
  - Permutation tests

**Announcements**:

- HW2 posted and due 2/11 at 10:00AM
- Final project due 5/1 at midnight



::: notes
Start homework 1!! It's computationally intensive. After this lecture you will have everything you need to start implementing it expect parallelization. You should have at least one simulation scenario tested and ready to go.

Question about homework 1?
Extra stuff in the Hesterburg paper that I didn't cover and is useful
:::

---

## Why do we need resampling methods?


- Inference requires understanding the **sampling distribution** of a statistic
- Classical tools rely on:
  - Known parametric models
  - Large sample (CLT-based) approximations
- In many modern settings: 
  - Sampling distributions are unknown
  - Asymptotics may be inaccurate or hard to obtain
  - Deriving standard errors is difficult or impossible

::: notes
Bootstrap is a resample

better confidence intervals when we can't get or don't trust ones based on CLT/ normal sampling theory

Confidence intervals are for parameter estimates (like $\hat{\beta}$)
:::

---

## Rivers t-test example

- `rivers` data: length (in miles) of 141 major North American Rivers

```{r, echo = FALSE, fig.height = 2, fig.width = 5}
data(rivers)


df <- data.frame(rivers = rivers)

mu  <- mean(rivers)
med <- median(rivers)
sdx <- sd(rivers)

ggplot(df, aes(x = rivers)) +
  geom_histogram(
    bins = 40,
    color = "black",
    fill = "grey80"
  ) +
  geom_vline(aes(xintercept = mu),
             color = "red", linewidth = 1) +
  geom_vline(aes(xintercept = med),
             color = "blue", linewidth = 1) +
  geom_vline(aes(xintercept = mu + sdx),
             linetype = "dashed", color = "red") +
  geom_vline(aes(xintercept = mu - sdx),
             linetype = "dashed", color = "red") +
  labs(
    title = "Red = mean ± 1 SD, Blue = median",
    x = "River length (miles)",
    y = "Count"
  ) +
  theme_minimal()
```


---

## Rivers t-test example

\fontsize{10pt}{11pt}\selectfont
Is the mean length of rivers in North America equal to 1000 miles?

- $H_0: \mu = 1000$ 

```{r, echo = FALSE}
t.test(rivers, mu = 1000)
```

---

## Rivers t-test example

\fontsize{10pt}{11pt}\selectfont
T-test assumptions

- Observations are independent
- CLT holds: sampling distribution of $\bar{Y}$ will be approximately normal even if the population isn't
- $\bar{Y}$ and $s$ are approximately independent

$$t = \frac{\bar{Y}-\mu}{s/\sqrt{n}}$$ 

- $t\sim t_{n-1} \mbox{ or } t\approx N(0,1)$


Highly skewed data violates these assumptions

- Mean and variance are correlated 
- Skewness is a property of the underlying distribution, not $n$, so increasing sample size won't necessarily fix the problem
  - Poor t-test coverage



::: notes
Popular rule of thumb is go to standard normal when n > 30

when data are skewed, SD and mean aren't independent- deleting a point from one of the extreme outliers changes the mean and variance

THis is a probem because basically everything we do in parameteric modeling is a t test
:::

----

##  Rivers t-test sampling distribution


```{r, echo = FALSE, fig.height = 3, fig.width = 5}
library(ggplot2)
library(patchwork)   # for side-by-side layout

data(rivers)
x <- rivers
n <- length(x)

# Point estimate and t-based SE
xbar <- mean(x)
s <- sd(x)
se <- s / sqrt(n)
df <- n - 1

# Bootstrap sampling distribution of the mean
set.seed(2026)
B <- 50000
boot_means <- replicate(B, mean(sample(x, replace = TRUE)))

boot_df <- data.frame(boot_mean = boot_means)

# t-based density for the mean
# If (Xbar - mu)/SE ~ t_df, then density of Xbar is:
t_density <- function(m) dt((m - xbar) / se, df = df) / se

# Plot limits based on bulk of bootstrap distribution
xlim <- quantile(boot_means, c(0.001, 0.999))

# ---- Left panel: histogram + t overlay ----
p_hist <- ggplot(boot_df, aes(x = boot_mean)) +
  geom_histogram(aes(y = after_stat(density)),
                 bins = 60, fill = "grey80", color = "black") +
  stat_function(fun = t_density, linewidth = 1) +
  geom_vline(xintercept = xbar, linewidth = 1) +
  coord_cartesian(xlim = xlim) +
  labs(
    title = "Sampling distribution",
    x = "Bootstrap means (miles)",
    y = "Density"
  ) +
  theme_minimal()

# ---- Right panel: Q–Q plot ----
# Standardize bootstrap means to t-scale
z_boot <- (boot_means - xbar) / se

probs <- ppoints(B)
emp_q <- quantile(z_boot, probs)
theo_q <- qt(probs, df = df)

qq_df <- data.frame(theo = theo_q, emp = emp_q)

p_qq <- ggplot(qq_df, aes(x = theo, y = emp)) +
  geom_point(size = 1, alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, linewidth = 1) +
  labs(
    title = "Q–Q plot",
    x = "Theoretical t quantiles",
    y = "Bootstrap quantiles"
  ) +
  theme_minimal()

# ---- Combine side by side ----
p_hist + p_qq

```

---

## Bootstrap: motivation

Suppose we observe data $Y_1\ldots Y_n \sim F$ and we want to compute a statistic $T(Y_1,\ldots Y_n)$.

We want:

- Standard errors
- Confidence intervals

- But $F$ is unknown
- The distribution of $T$ depends on $F$

**How can we approximate the sampling distribution of $T$ without knowing $F$?**

---


## Why classical asymptotics can fail

CLT-based inference assumes approximate normality of the test statistic. This can fail, even as $n \to \infty$ when:

- Data is skewed or heavy-tailed
- For nonlinear or non-smooth statistics (i.e. sample median vs. sample mean)

When these assumptions fail, asymptotics-based confidence intervals can have poor coverage.

- Also great for more complicated statistics where asymptotics can be hard to calculate

---



## When t is not t 

\fontsize{10pt}{11pt}\selectfont
When $Y_i$ come from a skewed distribution, the sample mean and its SE are correlated and their correlation does not decrease as $n\to \infty$

- $\implies$ t-statistic is not t-distributed

![](tdist.png){width=60%}


- If your test or CI assumes your statistic has a normal or t sampling distribution, **any deviation** from the diagonal implies your test/interval will perform poorly


::: notes
This is a Q-Q plot for a **sampling distribution** not raw data! The CLT already had its chance to work
:::

---


## When t is not t 

Idea: confidence intervals for parameter estimates provide no robustness against non-normality!

- Coverage does not improve as $n \to \infty$!


Bootstrapping can be very useful for constructing better confidence
intervals for these parameters.


::: notes
Tricky here because the non-normality refers to the sampling distribution of your test-statistic, not the underlying distribution of your data
:::

---


## A computational workaround

- We cannot repeatedly sample from the true population distribution $F$
- But, we *do* have data sampled from $F$

**Idea**: use the observed data to approximate $F$ through simulation

---

## Parameters as functionals


For some cumulative distribution function $F$, suppose we are
interested in a parameter, $\theta \stackrel{\triangle}{=} T(F)$, written as a functional of $F$


- A **functional** is a function of a function
  - Mean of $F$: $T(F) = \int y dF(y)$
  - Median of $F$: $T(F) = inf\{y: F(y) \ge 0.5\}$
- The statistic $T(Y_1,\ldots, Y_n)$ is an estimate of $T(F)$

Inference about a statistic is inference about a **functional of an unknown distribution.**


::: notes
Here  T(F) means some functional of f.  

inf is the infimum, which is the biggest number that is less than or equal to all elements of its set
This is our mathematical definition of the median in terms of the CDF

The idea here is that both the mean and the median (or other summary statistics we might be interested in) depend on the true underlying CDF of the data.
:::

---


## Estimating the data-generating distribution 


- The true distribution of $F$ is unknown, so we have to estimate it
- A natural estimator is the **empirical distribution**:

$$\hat{F}_n(y) = \frac{1}{n}\sum_{i = 1}^n I\{Y_i\le y\}$$

- $\hat{F}_n$ places $1/n$ mass at each observed data point
- To estimate a functional $T(F)$, we plug in the empirical distribution, $\hat{F}_n(y)$, for $F(y)$:

---

## The Bootstrap Principle

- Replace the unknown distribution $F$ with its estimate $\hat{F}_n$
- Approximate the sampling distribution of $T(Y_n,\ldots, Y_n)$ by:
  - Repeatedly sampling from $\hat{F}_n$
  - Recomputing the statistic



**Idea**: Bootstrap principle is used to estimate the sampling distribution of a *statistic* without relying on strong parametric assumptions about the underlying population distribution

::: notes
Used to estimate the sampling distribution of a statistic without relying on strong parametric assumptions about the underlying population distribution
:::

---

## What the bootstrap gives us


- Approximate sampling distribution
- Standard error estimates
- Confidence intervals

---

## The Bootstrap Principle

- Nonparametric bootstrap
- Parametric bootstrap
- Wild bootstrap


- Smooth bootstrap
- Bag of little bootstraps

::: notes
Many different flavors!
:::

---




## Nonparameteric bootstrap

\fontsize{10pt}{11pt}\selectfont
A **bootstrap sample** is a random sample of size drawn **with replacement** from $\hat F_n$

- Bootstrap sample denoted $y^* = (y^*_1, y^*_2, \ldots, y^*_n)$
- $\hat{\theta}^* \stackrel{\triangle}{=} T(\hat F_n(y^*))$ is the corresponding bootstrap estimate using the sample $y^*$
  - We'll call this $T(\hat F_n^*)$ to simplify notation
  

Draw $B$ bootstrap samples and calculate $\hat{\theta}^*_i, i = 1,\ldots,B$. 

- Then, SE of $\hat{\theta}$ can be estimated using the standard deviation of the $B$ replications:

$$\widehat{SE}(\hat{\theta}) = \sqrt{\frac{\sum_{i = 1}^B (\hat{\theta_i^*}-\bar{\theta}^*)^2}{B-1}}$$


::: notes
Then use this standard error or other aspects of the distribution of theta hat to estimate a confidence interval
:::

---


## Why does it work?

- $\hat F_n \to F$ uniformly by Glivenko-Cantelli
- $\implies$ when $n$ is large, sampling from $\hat F_n$ resembles sampling from $F$
  
  
- Potential sources of error:
  - Finite sample bias
  - Bootstrap distribution contains Monte Carlo error when exhaustive resampling is infeasible
    - For fixed $n$, number of possible bootstrap samples is ${2n-1}\choose{n}$


::: notes
Data sample needs to be representative of the population for it to work
Glivenko Cantelli establishes uniform convergence of the eCDF to the true CDF

Idea behind the bootstrap is simple but the theory is hard! I can point you to some resources if you want more.

if n = 10, choose(2n-1, n) = 92,378

if n = 5, 126
:::

---



## Sources of error


![](booterror.png){width=60%}

::: notes
One takeaway from this plot: bootstrap distribution is centered around $\bar{x}$, not $\mu$.  **Bootstrapping will not get you a better estimate of ** $\bar{x}$! Just a better estimate of the spread around it.

Also, there is error both due to your original sample, and due to the randomness in your bootstrap samples. The larger nboot is, the more you will reduce the second source of error. You can't really do anything about the first.
:::

---

## Example: nonparameteric bootstrap

\fontsize{10pt}{11pt}\selectfont
Using `mtcars` dataset, we will look at the mean `mpg` for different cars

```{r}
data(mtcars)
str(mtcars)
```


---

## Example: nonparameteric bootstrap


```{r, echo = FALSE, fig.width= 6, fig.height = 4, fig.align='center'}
hist(mtcars$mpg)
```



---

## Example: nonparameteric bootstrap

\fontsize{10pt}{11pt}\selectfont
```{r}
B = 10000
mpg = mtcars$mpg
boot_mean = rep(NA, B)
set.seed(222)
for(i in 1:B){
  ystar = sample(mpg, size = length(mpg), replace = TRUE)
  boot_mean[i] = mean(ystar)
}

paste0("mean: ", round(mean(mpg),3), 
       "; bootstrapped mean: ", round(mean(boot_mean),3))
```


::: notes
Formula for standard error of the mean is s/sqrt(n) where s is the sample standard deviation
depends on large enough sample size and/or normal mpg variable

Standard deviation of the bootstrapped estimates is an estimate of the standard error of theta hat
:::

---

## Example: nonparameteric bootstrap

\fontsize{10pt}{11pt}\selectfont

```{r}
se_mean = sd(mpg)/sqrt(length(mpg))
paste0("sd: ", round(se_mean,3), 
       "; bootstrapped sd: ", round(sd(boot_mean),3))
```

---


## Example: nonparameteric bootstrap

```{r, fig.width= 5, fig.height = 3, fig.align='center'}
hist(boot_mean)
```


---





## Bootstrap confidence intervals

- When it works, the bootstrap can be very useful for constructing
confidence intervals (CIs) for a parameter $\theta$


- Multiple methods for constructing bootstrap CIs exist!
  - Percentile intervals
  - $t$ intervals with bootstrap SE (also called Wald-type)
  - bootstrap $t$
  - BCa intervals
  

- Quality of different approaches generally depends on $n$ and the skewness of the original data


---

## Order of accuracy

- Recall "big-O" notation for non-negative functions $f,g$:
  - $f(x) \in O(g(x)) \mbox{ iff } f(x) \le hg(x) \forall x\ge x_0$ and some $h > 0$
  

- A confidence interval is **first-order accurate** if the non-coverage probability differs from the nominal value by $O(n^{-1/2})$:
  - $Pr(\theta < \theta_{lb}) + P(\theta > \theta_{ub}) = \alpha + O(n^{-1/2})$
  
  
- A confidence interval is second-order accurate if the non-coverage probability differs from the nominal value by $O(n^{-1})$:
  - $Pr(\theta < \theta_{lb}) + P(\theta > \theta_{ub}) = \alpha + O(n^{-1})$

::: notes
Basically, this just means that the second order accurate confidence intervals converge faster as n increases than the second order intervals.
:::

---


## Percentile method

The simplest approach to constructing a bootstrap CI is the **percentile method**.

- Let $\hat{\theta}^*_1, \ldots, \hat{\theta}^*_B$ be a bootstrap sample of point estimators
- Then, a two-sided $100 \times (1-\alpha)$% bootstrap percentile CI is 

$$(\xi^*_{\alpha/2}, \xi^*_{1-\alpha/2})$$

- where $\xi^*_p$ is the $p^{th}$ percentile of the bootstrap samples


---

## Percentile method

**Pros**:

- Simple to implement and easy to understand
- It is **transformation invariant**: the percentile method confidence interval for a monotone transformation of $\theta$ can be obtained by transforming the endpoints of the interval for $\theta$
- Works better than some other methods when data are skewed


**Cons**:

- Tends to be too narrow with small sample sizes
- The percentile method is only first-order accurate


::: notes
Think about transformation invariant in terms of logistic regression: you might want a confidence interval for both beta and e^beta (the odds ratio)

What does too narrow mean, practically? Poor coverage. False rejection of null hypothesis (type 1 error)
::: 

---

## $t$ intervals with bootstrap SE

Recall that if $(\hat{\theta}-\theta)/\hat{se}(\hat{\theta}) \to N(0,1)$, then the (Wald) approximate CI for $\theta$ is 

$$\hat{\theta} \pm Z_{1-\alpha/2}\times se(\hat{\theta)}$$

- This interval will closely agree with the percentile bootstrap CI when $\hat{\theta}$ is approximately normal
- What if we don't know $se(\hat{\theta)}$ or $se(\hat{\theta)}$ is difficult to calculate?

---

## $t$ intervals with bootstrap SE

When $se(\hat{\theta)}$ is unknown or cumbersome, we can use a bootstrap estimate of the standard error of $\hat{\theta}$ instead:

$$\hat{\theta} \pm Z_{1-\alpha/2}\times \hat{se}_b(\hat{\theta)}$$

- For smaller samples, replace the $Z$ quantile by a $t$ quantile:

$$\hat{\theta} \pm t_{1-\alpha/2, n-1}\times \hat{se}_b(\hat{\theta})$$

- If you can estimate $se(\hat{\theta)}$ directly, there is no real benefit of using $\hat{se}_b(\hat{\theta})$

---

## $t$ intervals with bootstrap SE

**Pros**:

- Simple to implement and easy to understand
- Can be applied to situations where $se(\hat{\theta)}$ is difficult to derive


**Cons**:

- **Biased**: comparable to using the MLE $\sqrt{\frac{1}{n}\sum_i (x_i-\bar{x})^2}$ instead of the unbiased estimate $\sqrt{\frac{1}{n-1}\sum_i (x_i-\bar{x})^2}$
- Can perform poorly if distribution is skewed
- Tends to be too narrow with small sample sizes
- Only first-order accurate


---

## Bootstrap $t$ method

The **bootstrap-t** method uses simulation to estimate the $t$ quantile for the interval.

- For **each** bootstrap sample, calculate $t^*_b$, where:
  - $t^*_b = \frac{\hat{\theta}^*_b-\hat{\theta}}{se(\hat{\theta}^*_b)}$
  - $\hat{\theta}$ is estimated from the original sample
  - $\hat{\theta}^*_b$ is estimated from the $b^{th}$ bootstrap sample
  - $se(\hat{\theta}^*_b)$ is the SE of the $b^{th}$ estimate
  
::: notes
This is different from the previous approach, t intervals with bootstrap SE!!
Notation here is key to understand, this one is going to show up in your homework
:::

---

## Bootstrap $t$ method

The **bootstrap-t** method uses simulation to estimate the $t$ quantile for the interval.

- For **each** bootstrap sample, calculate $t^*_b$, where:
  - $t^*_b = \frac{\hat{\theta}^*_b-\hat{\theta}}{se(\hat{\theta}^*_b)}$
  - $\hat{\theta}$ is estimated from the original sample
  - $\hat{\theta}^*_b$ is estimated from the $b^{th}$ bootstrap sample
  - $se(\hat{\theta}^*_b)$ is the SE of the $b^{th}$ estimate
  

- Since $se(\hat{\theta}^*_b)$ is unknown, must estimate it...

---

## Bootstrap $t$ method

\fontsize{10pt}{11pt}\selectfont
Note that calculating $\hat{se}(\hat{\theta}^*_b)$ for each bootstrap estimate requires (nested) bootstrapping!

- Obtain a bootstrap estimate of $se(\hat{\theta}^*_b)$ for **each** $b = 1, \ldots, B$
  - For each bootstrap sample $b$, run $k = 1, \ldots, K$ bootstrap simulations to obtain $\hat{\theta}_{b,k}^*$ and use these to estimate  $se(\hat{\theta}^*_b)$ for calculating $t^*_b$
- Calculate lower and upper quantiles of the *bootstrap t distribution*, $t^*_{1-\alpha/2}$ and $t^*\alpha/2$ and construct the CI:

$$\left(\hat{\theta}-t^*_{1-\alpha/2}\times se(\hat{\theta)}, \hat{\theta}-t^*_{\alpha/2}\times se(\hat{\theta)}\right)$$

- $se(\hat{\theta})$ is the SE of the estimate from the original sample, or can be estimated using the top-level bootstrap



---


## Bootstrap $t$ method

\fontsize{10pt}{11pt}\selectfont
**Pros**:

- Second-order accurate
- Usually outperforms the other methods discussed so far, especially for non-normal populations.
- For skewed data, much more asymmetric than the percentile bootstrap interval which corrects for the possibility that we observed too few observations from the tail


**Cons**:

- Requires an iterated bootstrap
- The bootstrap-t interval is not transformation invariant. Must reconstruct the CI for a function of the parameter $g(\theta)$


---



## BCa Bootstrap

\fontsize{10pt}{11pt}\selectfont
The bias-corrected accelerated (BCa) method is an improvement over the percentile method, though still does not work well in small sample sizes.

- BCa intervals use percentiles of the bootstrap distribution, but not necessarily the $100 \times \alpha$-th and $100\times (1-\alpha)$-th percentiles
- Adjusts for **bias** in the bootstrap distribution and variability in the precision of the estimate (aka **acceleration**)

First, estimate a bias correction factor $\hat{z}_0$:

$$\hat{z}_0 = \Phi^{-1}\left(\frac{\#\{\hat{\theta}^*<\hat{\theta}\}}{B}\right)$$

- The acceleration parameter measures how the estimator’s variability changes with the true parameter

::: notes
Bias correction. based on the proportion of bootstrap sample estimates that are less than the original sample estimate.
:::

---

## BCa Bootstrap

Next, estimate the acceleration parameter $\hat{a}$:

$$\hat{a} = \frac{\sum_{i=1}^n(\hat{\theta}_{(.)}-\hat{\theta}_{(i)})^3}{6\left(\sum_{i=1}^n (\hat{\theta}_{(.)}-\hat{\theta}_{(i)})^2\right)^{3/2}}$$

- $\hat{\theta}_{(i)}$ is the value of the statistic with the $i^{th}$ observation removed (i.e. the $i^{th}$ jackknife estimate)
- $\hat{\theta}_{(.)}$ is the mean of the $n$ jackknife estimates

- adjusts for the rate of change in the standard error as the estimate changes


---

## BCa Bootstrap

\fontsize{10pt}{11pt}\selectfont
After estimating the bias correction $\hat{z}_0$ and acceleration $\hat{a}$, compute:

$$\alpha_1 = \Phi\left(\hat{z}_0 + \frac{\hat{z}_0 + z_{\alpha/2}}{1-\hat{a}(\hat{z}_0 + z_{\alpha/2})}\right)$$


$$\alpha_2 = \Phi\left(\hat{z}_0 + \frac{\hat{z}_0 + z_{1-\alpha/2}}{1-\hat{a}(\hat{z}_0 + z_{1-\alpha/2})}\right)$$

- $\Phi$ is the standard normal CDF (`pnorm`)
- $z_a$ is the $100\times \alpha$-th percentile of the standard normal
- Use these new percentiles to construct a CI
  - The BCa interval is the same as the percentile interval when $\hat{a} = \hat{z}_0 = 0$

---


## BCa Bootstrap

\fontsize{10pt}{11pt}\selectfont
**Pros**:

- Second-order accurate and transformation invariant
- Works well for a variety parameters
- For skewed data, the percentile bootstrap is not asymmetric
enough and the BCa bootstrap addresses this limitation
- Implemented in the `bcanon()` function in the `bootstrap` R library



**Cons**:

- Estimation of the acceleration parameter requires the jackknife
- Less intuitive than other methods
- Still doesn't work great for small sample sizes

::: notes
Considered the gold standard for nonparametric bootstrap methods
:::

---



## Parametric bootstrap


If we have information about the population distribution, this can be
used in resampling for bootstrap inference

- If the assumption about the population distribution is correct then
the parametric bootstrap will perform better than the
nonparametric bootstrap

- If the assumption not correct, then the nonparametric bootstrap should perform better.

---

## Parametric bootstrap example

\fontsize{10pt}{11pt}\selectfont
Suppose we have data from a $N(\mu, \sigma^2)$ distribution, $Y = \{y_1, \ldots, y_n\}$

- Interested in obtaining an estimate of the standard error of the
trimmed mean with 10% trimmed from each tail
- To employ the parametric bootstrap, we would start by generating $n$ values from a $N(\hat{\mu}, \hat{\sigma}^2)$
  - $\hat{\mu}, \hat{\sigma}^2$ are the ML estimates
- Then, compute trimmed mean using the simulated sample
  - repeat B times



Only difference between parametric and non-parametric bootstrap is the way to generate data!


::: notes
Note that no replacement is done here

In parametric bootstrap: simulate from parametric distribution
In non-parametric: sample with replacement from observed data
Still can use same means of getting confidence intervals
:::

---

## Bootstrapping regression models

Regression model:

$$E(Y_i|\textbf{X}_i) = f(\mathbf{\beta}, \textbf{X}_i), i = 1,\ldots, n$$



- $f$ is a known function, $\textbf{X}_i$ a vector of parameters
- Interested in estimating a SE or CI for a function of parameters


::: notes
Generalizes to logistic regression, etc
:::

---


## Bootstrapping regression models

Three common methods:

1. Bootstrap the pairs $(Y_i, \textbf{X}_i)$ and generate bootstrap
parameter estimates that can be used to obtain bootstrap CIs

2. Bootstrap the **residuals** of the original model

3. Estimate the residual variance and simulate residuals


::: notes
Are these parametric or nonparametric bootstrap approaches?
:::

---

## Bootstrapping regression models: residuals 

\fontsize{10pt}{11pt}\selectfont
Let's take linear regression as an example, 

$$Y_i = \textbf{X}_i^T\mathbf{\beta} + \epsilon_i; \epsilon_i \sim N(0, \sigma^2)$$

To fit a bootstrap on the residuals:

- Fit a model on the original data to obtain residuals $\hat{\epsilon}_i$
  - $\hat{\epsilon}_i = Y_i - \textbf{X}_i^T\hat{\mathbf{\beta}}$
- Resample residuals $\hat{\epsilon}_i$ with replacement and repeat $B$ times:
  - Compute $Y_i^b = \textbf{X}_i^T\hat{\mathbf{\beta}}+ \hat{\epsilon}_i^b$ for all $i$
  - Refit model using $Y_i^b, i = 1,\ldots, n$ to estimate $\hat{\beta}^b$
- This approach assumes errors are **identically distributed**



::: notes
This is the approach where we bootstrap the residuals of the original model
Advantage: Y's and X's are fixed rather than random, which is sometimes consistent with assumptions
:::

---


## Bootstrapping regression models: residual variance 

- Estimate residual variance from sample, $\hat{\sigma}^2$
- Repeat $B$ times:
  - Generate a residual $\epsilon^b_i \sim N(0, \hat{\sigma}^2)$ and associated outcome $Y_i^b = \textbf{X}_i^T\hat{\mathbf{\beta}} + \epsilon^b_i$ for $i = 1,\ldots, n$
  - Refit model using $Y_i^b$, $i = 1, \ldots, n$ to estimate $\hat{\beta}^b$


This approach assumes the residual errors are **normally distributed** 

::: notes
This is the third approach, where we estimate residual variance
:::

---




## Wild bootstrap

\fontsize{10pt}{11pt}\selectfont
$$Y_i = \textbf{X}_i^T\mathbf{\beta} + \epsilon_i$$
The models previously discussed fail if there is **heteroskedasticity**
- i.e., if $\epsilon_i$ are not identically distributed

The **wild bootstrap** is a modification of the residual bootstrap intended to handle heteroskedasticity.

- Fit a model on the original data to obtain residuals $\hat{\epsilon}_i$
- Repeat $B$ times:
  - Multiply residuals by random weights to obtain $\hat{\epsilon}_i^b$
  - Compute $Y_i^b = \textbf{X}_i^T\hat{\mathbf{\beta}}+ \hat{\epsilon}_i^b$ for all $i$
  - Refit model using $Y_i^b, i = 1,\ldots, n$ to estimate $\hat{\beta}^b$



---

## Wild bootstrap

Common options for weights:


1. Multiply $\hat{\epsilon}_i$ by $-1$ or $1$ with equal probability


2. Multiply $\hat{\epsilon}_i$ by a standard normal random variable

---



## When does the bootstrap fail?

We must assume that the original sample is representative of the population so that $\hat{F}_n$ is a good estimate of $F$


The bootstrap may fail when:

- The support of $F$ depends on the parameter of interest
- The true parameter sits on the boundary of the parameter space
- The parameter of interest is nonregular, i.e., there does not exist
an estimator that converges to it uniformly in distribution over
the parameter space


---

## Permutation tests

\fontsize{10pt}{11pt}\selectfont
Typically bootstrap is used for CI rather than hypothesis testing.  For hypothesis testing and p-values, we can use a **permutation test**.
- Idea: use resampling to generate a **null distribution** for a test statistic, then compare it to the one you observe in the real data

- **Null distribution**: the distribution of a quantity of interest (i.e. $\hat{\beta}$) if the null hypothesis $H_0$ is true

- The null distribution is available theoretically in some cases. For example,
assume $Y_i \sim N(\mu, \sigma^2), i = 1,\ldots,n$.  
  - Under $H_0: \mu = 0$, we have $\bar{Y} \sim N(0, \sigma^2/n)$
    - Test $H_0$ by comparing $\bar{Y}$ with $N(0, \sigma^2/n)$

- Use **permutation test** when null distribution cannot be obtained theoretically 



::: notes
This is a different resampling approach
We can use bootstrap for p-values but this isn't as common
:::

---


## Permutation tests

The basic procedure of permutation test for $H_0$:

- Permute data under $H_0$ $B$ times. Each time recompute the test
statistics. The test statistics obtained from the permuted data form the null distribution.
- Compare the observed test statistics with the null distribution to obtain statistical
significance.



---


## Permutation test example

\fontsize{10pt}{11pt}\selectfont
Assume there are two sets of independent normal r.v.’s with the same known
variance and different means:

- $X_i \sim N(\mu_1,\sigma^2)$
- $Y_i \sim N(\mu^2, \sigma^2)$

Our goal is to test $H_0: \mu_1 = \mu_2$.  Define test statistic: $t = \bar{X}-\bar{Y}$. Permutation test steps:

1. Randomly shuffle labels of $X$ and $Y$
2. Compute $t^* = \bar{X}^*-\bar{Y}^*$
3. Repeat `nperm` times. Resulting $t^*$ values form the **empirical null distribution** of $t$.
4. To compute p-values calculate $Pr(|t^*|> |t|)$





