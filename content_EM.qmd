---
title: "Optimization: EM and MM Algorithms"
format:
  html:
    toc: true
    toc-location: right
execute:
  echo: false
  fig-width: 6
  fig-asp: 0.6
  out-width: "90%"
---



## Overview

In this, we will focus on the EM and MM algorithms.


::: {.panel-tabset .panel-pills}

### Slide Deck: Introduction to the Expectation-Maximization (EM) Algorithm

[![](./slides/topic_optimization/preview_EM.png){width=70%}](./slides/topic_optimization/s_EM.pdf)

**Intro EM**  
[Download slides (PDF)](./slides/topic_optimization/s_EM.pdf)


***

### Slide Deck: EM Theory

[![](./slides/topic_optimization/preview_EM_theory.png){width=70%}](./slides/topic_optimization/s_EM_theory.pdf)

**EM Theory**  
[Download slides (PDF)](./slides/topic_optimization/s_EM_theory.pdf)


***


### Slide Deck: MM

[![](./slides/topic_optimization/preview_MM.png){width=70%}](./slides/topic_optimization/s_MM.pdf)

**MM**  
[Download slides (PDF)](./slides/topic_optimization/s_MM.pdf)


***

### Lab: EM


#### Exercise 1: Two-component Gaussian mixture model

This will use the example given in Lecture for the two component GMM.  Your role will be to modify the code `EM_GMM.R`.  


In this code, we are implementing a two component Gaussian mixture model to fit to the Old Faithful Geyser dataset.  This dataset provides the waiting time between eruptions for Old Faithul in Yellowstone National Park.  Notice that the waiting times between eruptions have a bimodal distribution:


```{r}
library(tictoc)
data(faithful)
hist(faithful$waiting)
```


We will use a GMM to find the mean and variance of the two modes (assumption a Gaussian distribution or each mode), and assign a probability that each waiting time belongs to each mode.  


Open the code `EM_GMM.R` and do the following:


- Complete the E-step of the EM algorithm (M-step is already complete)
- Add in tolerance criteria to the `while` loop
  - What likelihood should we be monitoring for convergence?
  - Plot this likelihood at each iteration.  Is it monotonic?

- Once your code is complete, try out different initialization parameters. Do you get to the same answer? 



#### Exercise 2: Censored exponential data


Suppose we have survival times $t_1, \ldots, t_n \sim Exponential(\lambda)$. 

* Do not observe all survival times because some are censored at times $c_1, \ldots, c_n$.  
* Actually observe $y_1, \ldots, y_n$, where $y_i = min(y_0, c_i)$
  * Also have an indicator $\delta_i$ where $\delta_i = 1$ is $y_i \le c_i$
    * i.e. $\delta_i = 1$ if not censored and $\delta_i = 0$ if censored

<br>

* What is $p(y, z |\theta)$, the complete data density?


* What is $z$?

* Set up the function $Q(\lambda|\lambda_0)$


#### Exercise 3: EM Standard Errors

We will use a GMM to find the mean and variance of the two modes (assumption a Gaussian distribution or each mode), and assign a probability that each waiting time belongs to each mode.  


Open the code `EM_GMM.R` and do the following:

- Implement bootstrap standard errors for parameters $\theta$

- Try out Louis's method or SEM


***

### Lab: MM


#### **Exercise 1**: MM for sample median

The code below performs implements an MM algorithm for finding the sample median.  Simulate data with a true median of $\theta$. Compare the MM algorithm with the median value obtained using `median()`



- you may note that the MM value is different from that obtained using `median()`. Why?


```{r}
## simulate some data
n = 1000001
true_median = 5
y = rnorm(n, true_median)   # symmetric dist, so mean = median
```



```{r, eval = FALSE, echo = TRUE}
iter = 1
tol_criteria = Inf

# define vectors to store elements of interest
max_iter = 100
tol = 0.00001
surrogate = objective = theta_vec = rep(NA, length = max_iter)


## Add initial value
theta0 = 100
theta = theta0
####

tic()
while(iter < max_iter  & tol_criteria > tol){

  ###############################################################
  ## Majorization
  ###############################################################

  surrogate[iter] = 1/2 *sum((y-theta)^2/abs(y-theta) + abs(y-theta))
  objective[iter] = sum(abs(y - theta))
  w = 1/abs(y-theta)

  ###############################################################
  ## Minimization
  ###############################################################

  theta = sum(w * y)/sum(w)
  theta_vec[iter] = theta
  ###############################################################

  if(iter > 1){
    tol_criteria = abs(objective[iter] - objective[iter-1])
  }
  iter = iter + 1
  message(paste0("iteration: ", iter, "; ll: ", round(tol_criteria, 4)))
}

time_mm = toc()


```


```{r, eval = FALSE, echo = TRUE}
tic()
median(y)
time_med = toc()
time_med$toc- time_med$tic


theta
time_mm$toc- time_mm$tic

```


#### **Exercise 2**: MM for Bradley-Terry ranking

The `baseball` dataset has baseball results for 7 teams from the 1987 season.   

```{r}
library(BradleyTerry2)

data(baseball)
head(baseball)
```


Modify code above to implement solution to Bradley-Terry ranking. Estimate the Ranking comparing Milwaukee to New York and Milwaukee to Boston.



:::
