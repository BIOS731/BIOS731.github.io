[
  {
    "objectID": "topic_bayesian_computing.html",
    "href": "topic_bayesian_computing.html",
    "title": "Bayesian Computing",
    "section": "",
    "text": "In progress."
  },
  {
    "objectID": "content_simulations.html",
    "href": "content_simulations.html",
    "title": "Simulations and resampling methods",
    "section": "",
    "text": "In this, we will cover basic simulations, bootstrapping, permutation tests, and speeding up code through vectorization and parallelization.\n\nSlide Deck: SimulationsSlide Deck: BootstrapSlide Deck: Benchmarking and parallelizationLab: simulationsLab: resampling methodsLab: Benchmarking and parallelization\n\n\n\nSimulation studies\nDownload slides (PDF)\n\n\n\n\nResampling Methods\nDownload slides (PDF)\n\n\n\n\nSpeeding up your code in R\nDownload slides (PDF)\n\n\n\nSimulation study workflow\nFirst, use ADEMP guidelines to define the following\n\nSimulation scenarios\nEstimands/targets\nPerformance measures\n\nThen, for a given simulation scenario follow the basic steps:\n\nChoose \\(n_{sim}\\)\nSimulate data\nApply method(s)\nCalculate estimates\nStore results\n\nWhenever possible, separate scripts for performing different tasks.\n\n\nOur goal in this exercise will be to plan a well-organized simulation study for multiple linear regression. It will be similar in structure to your Homework 2. Below is a multiple linear regression model, where we are interested in primarily treatment effect.\n\\[Y_i = \\beta_0 + \\beta_{treatment}X_{i1} + \\mathbf{Z_i}^T\\boldsymbol{\\gamma} + \\epsilon_i\\]\n\n\\(Y_i\\): continuous outcome\n\\(X_{i1}\\): treatment group indicator; \\(X_{i1}=1\\) for treated\n\\(\\mathbf{Z_i}\\): vector of potential confounders\n\n\n\n\\(\\beta_{treatment}\\): average treatment effect, adjusting for \\(\\mathbf{Z_i}\\)\n\\(\\boldsymbol{\\gamma}\\): vector of regression coefficient values for confounders\n\\(\\epsilon_i\\): iid error, \\(\\sim N(0, \\sigma^2)\\)\n\nIn our simulation, we want to\n\nEstimate \\(\\beta_{treatment}\\)\n\nEvaluate through bias and coverage\n\nEstimate \\(\\sigma^2\\)\n\nEvaluate through bias\n\nEvaluate these properties at:\n\nSample size \\(n \\in \\{10, 50, 500\\}\\)\nTrue values \\(\\beta_{treatment} \\in \\{0.5, 2\\}\\)\nTrue values \\(\\sigma^2 \\in \\{1, 5\\}\\)\n\nAssume for now that there are no confounders (\\(\\boldsymbol{\\gamma} = 0\\))\nAssume \\(X_{i1} = 1\\) with probability 0.5\nUse a full factorial design\n\n\n\n\n\nHow many simulation scenarios will you be running?\nWhat are the estimand(s)\nWhat method(s) are being evaluated/compared?\nWhat are the performance measure(s)?\n\n\n\n\nBased on desired coverage of 90% with Monte Carlo error of no more than 1%, how many simulations (\\(n_{sim}\\)) should we perform for each simulation scenario?\n\n\n\nI’ve created an example project folder for running simulations using similar structure from the project organization lecture. Download it here. Unzip and save in an organized location- this will become its own GitHub repository.\nNext, start implementing your simulation study! Write separate scripts for simulating data, applying the method, and extracting estimates.\nFor now, choose just one simulation scenario to implement. If you have time, you can implement others.\n\n\n\nAggregate simulation results. Use informative tables and/or figures to summarize results.\n\n\n\n\n\nTake the following problem from the slides:\nSuppose we have data from a \\(N(\\mu, \\sigma^2)\\) distribution, \\(Y = \\{y_1, \\ldots, y_n\\}\\)\n\nInterested in obtaining an estimate of the standard error of the trimmed mean with 10% trimmed from each tail\nTo employ the parametric bootstrap, we would start by generating \\(n\\) values from a \\(N(\\hat{\\mu}, \\hat{\\sigma}^2)\\)\n\n\\(\\hat{\\mu}, \\hat{\\sigma}^2\\) are the ML estimates\n\nThen, compute trimmed mean using the simulated sample\n\nrepeat B = 10000 times\n\n\n\n\nImplement both the parametric and non-parametric bootstrap for the trimmed mean here. Compare standard error estimates. Which do you expect to perform better? How would you evaluate what is “better”?\n\n\n\nFor the non-parametric bootstrap, construct bootstrap-t confidence intervals for the trimmed mean using B = 1000 for the first level bootstrap and Bt = 500 for the second level bootstrap.\n\n\n\n\nAssume there are two sets of independent normal random variables with the same known variance and different means:\n\n\\(X_i \\sim N(\\mu_1,\\sigma^2)\\)\n\\(Y_i \\sim N(\\mu^2, \\sigma^2)\\)\n\nOur goal is to test \\(H_0: \\mu_1 = \\mu_2\\). Define test statistic: \\(t = \\bar{X}-\\bar{Y}\\). Permutation test steps:\n\nRandomly shuffle labels of \\(X\\) and \\(Y\\)\nCompute \\(t^* = \\bar{X}^*-\\bar{Y}^*\\)\nRepeat nperm times. Resulting \\(t^*\\) values form the empirical null distribution of \\(t\\).\nTo compute p-values calculate \\(Pr(|t^*|&gt; |t|)\\)\n\n\n\n\n\n\n\n\nCreate a function square_for(x) that takes as an argument vector x (of any length), and uses the for loop to return vector y such that \\[y_i = x_i^2\\]\nCreate a function square_sapply(x) that does the same thing using sapply function.\nCreate a function square_vec(x) that does the same thing using ^ operator applied directly to vector x.\nCreate a function square_vec2(x) that does the same thing using * operator applied directly to vector x.\nCreate a vector x of \\(p=100,000\\) normal random variables\n\nNext, use microbenchmark package to compare the performance of the four functions above using x\nWhat’s your conclusion?\n\n\n\nGo back to the lab on simulations. You can start with the solutions file, listed as partial_solution on the canvas site. Parallelize this code."
  },
  {
    "objectID": "content_simulations.html#overview",
    "href": "content_simulations.html#overview",
    "title": "Simulations and resampling methods",
    "section": "",
    "text": "In this, we will cover basic simulations, bootstrapping, permutation tests, and speeding up code through vectorization and parallelization.\n\nSlide Deck: SimulationsSlide Deck: BootstrapSlide Deck: Benchmarking and parallelizationLab: simulationsLab: resampling methodsLab: Benchmarking and parallelization\n\n\n\nSimulation studies\nDownload slides (PDF)\n\n\n\n\nResampling Methods\nDownload slides (PDF)\n\n\n\n\nSpeeding up your code in R\nDownload slides (PDF)\n\n\n\nSimulation study workflow\nFirst, use ADEMP guidelines to define the following\n\nSimulation scenarios\nEstimands/targets\nPerformance measures\n\nThen, for a given simulation scenario follow the basic steps:\n\nChoose \\(n_{sim}\\)\nSimulate data\nApply method(s)\nCalculate estimates\nStore results\n\nWhenever possible, separate scripts for performing different tasks.\n\n\nOur goal in this exercise will be to plan a well-organized simulation study for multiple linear regression. It will be similar in structure to your Homework 2. Below is a multiple linear regression model, where we are interested in primarily treatment effect.\n\\[Y_i = \\beta_0 + \\beta_{treatment}X_{i1} + \\mathbf{Z_i}^T\\boldsymbol{\\gamma} + \\epsilon_i\\]\n\n\\(Y_i\\): continuous outcome\n\\(X_{i1}\\): treatment group indicator; \\(X_{i1}=1\\) for treated\n\\(\\mathbf{Z_i}\\): vector of potential confounders\n\n\n\n\\(\\beta_{treatment}\\): average treatment effect, adjusting for \\(\\mathbf{Z_i}\\)\n\\(\\boldsymbol{\\gamma}\\): vector of regression coefficient values for confounders\n\\(\\epsilon_i\\): iid error, \\(\\sim N(0, \\sigma^2)\\)\n\nIn our simulation, we want to\n\nEstimate \\(\\beta_{treatment}\\)\n\nEvaluate through bias and coverage\n\nEstimate \\(\\sigma^2\\)\n\nEvaluate through bias\n\nEvaluate these properties at:\n\nSample size \\(n \\in \\{10, 50, 500\\}\\)\nTrue values \\(\\beta_{treatment} \\in \\{0.5, 2\\}\\)\nTrue values \\(\\sigma^2 \\in \\{1, 5\\}\\)\n\nAssume for now that there are no confounders (\\(\\boldsymbol{\\gamma} = 0\\))\nAssume \\(X_{i1} = 1\\) with probability 0.5\nUse a full factorial design\n\n\n\n\n\nHow many simulation scenarios will you be running?\nWhat are the estimand(s)\nWhat method(s) are being evaluated/compared?\nWhat are the performance measure(s)?\n\n\n\n\nBased on desired coverage of 90% with Monte Carlo error of no more than 1%, how many simulations (\\(n_{sim}\\)) should we perform for each simulation scenario?\n\n\n\nI’ve created an example project folder for running simulations using similar structure from the project organization lecture. Download it here. Unzip and save in an organized location- this will become its own GitHub repository.\nNext, start implementing your simulation study! Write separate scripts for simulating data, applying the method, and extracting estimates.\nFor now, choose just one simulation scenario to implement. If you have time, you can implement others.\n\n\n\nAggregate simulation results. Use informative tables and/or figures to summarize results.\n\n\n\n\n\nTake the following problem from the slides:\nSuppose we have data from a \\(N(\\mu, \\sigma^2)\\) distribution, \\(Y = \\{y_1, \\ldots, y_n\\}\\)\n\nInterested in obtaining an estimate of the standard error of the trimmed mean with 10% trimmed from each tail\nTo employ the parametric bootstrap, we would start by generating \\(n\\) values from a \\(N(\\hat{\\mu}, \\hat{\\sigma}^2)\\)\n\n\\(\\hat{\\mu}, \\hat{\\sigma}^2\\) are the ML estimates\n\nThen, compute trimmed mean using the simulated sample\n\nrepeat B = 10000 times\n\n\n\n\nImplement both the parametric and non-parametric bootstrap for the trimmed mean here. Compare standard error estimates. Which do you expect to perform better? How would you evaluate what is “better”?\n\n\n\nFor the non-parametric bootstrap, construct bootstrap-t confidence intervals for the trimmed mean using B = 1000 for the first level bootstrap and Bt = 500 for the second level bootstrap.\n\n\n\n\nAssume there are two sets of independent normal random variables with the same known variance and different means:\n\n\\(X_i \\sim N(\\mu_1,\\sigma^2)\\)\n\\(Y_i \\sim N(\\mu^2, \\sigma^2)\\)\n\nOur goal is to test \\(H_0: \\mu_1 = \\mu_2\\). Define test statistic: \\(t = \\bar{X}-\\bar{Y}\\). Permutation test steps:\n\nRandomly shuffle labels of \\(X\\) and \\(Y\\)\nCompute \\(t^* = \\bar{X}^*-\\bar{Y}^*\\)\nRepeat nperm times. Resulting \\(t^*\\) values form the empirical null distribution of \\(t\\).\nTo compute p-values calculate \\(Pr(|t^*|&gt; |t|)\\)\n\n\n\n\n\n\n\n\nCreate a function square_for(x) that takes as an argument vector x (of any length), and uses the for loop to return vector y such that \\[y_i = x_i^2\\]\nCreate a function square_sapply(x) that does the same thing using sapply function.\nCreate a function square_vec(x) that does the same thing using ^ operator applied directly to vector x.\nCreate a function square_vec2(x) that does the same thing using * operator applied directly to vector x.\nCreate a vector x of \\(p=100,000\\) normal random variables\n\nNext, use microbenchmark package to compare the performance of the four functions above using x\nWhat’s your conclusion?\n\n\n\nGo back to the lab on simulations. You can start with the solutions file, listed as partial_solution on the canvas site. Parallelize this code."
  },
  {
    "objectID": "topic_optimization_II.html",
    "href": "topic_optimization_II.html",
    "title": "Optimization, Part II",
    "section": "",
    "text": "In progress."
  },
  {
    "objectID": "topic_optimization.html",
    "href": "topic_optimization.html",
    "title": "Optimization, Part 1",
    "section": "",
    "text": "Is this module we will first cover convex optimization and gradient descent. In the second week of this module we will move to the EM and MM algorithms.\n\nIntroduction to optimization and gradient descent\nEM 1: Applications\nEM 2: Theory and Inference\nMM Algorithm"
  },
  {
    "objectID": "content_repro.html",
    "href": "content_repro.html",
    "title": "A Crash Course in Reproducible Computing",
    "section": "",
    "text": "In this, we will cover basic topics in reproducible computing, including coding style, project organization, and git/GitHub.\n\nSlide Deck: project organizationSlide Deck: git/GithubLab: projectrLab: CDC open data\n\n\n\nCrash course on reproducible computing in R\nDownload slides (PDF)\n\n\n\n\nCrash course on reproducible computing in R\nDownload slides (PDF)\n\n\n\nI asked ChatGPT to write me some code for creating a reproducible file structure for a new project. The prompt I used is below:\n\nCan you write me an R function that will take in a filepath, and name for a new directlry then create a new directory with that same that includes subfolders called “analysis”, “source”, “data”, “results”, and “literature”, and also contains an initialized .git repo, a .Rproj file with the same name as the new directory in the root, and a README.md file?\n\nBelow is the code it wrote me. What is it doing? Modify it to suit your own preferences, and see if it works!\n\nAlso, we just spent a while talking about coding practices. What do you like about this code? What do you dislike?\n\n\ncreate_r_project_skeleton &lt;- function(base_path,\n                                      project_name,\n                                      open_rproj = FALSE,\n                                      git = TRUE) {\n  stopifnot(is.character(base_path), length(base_path) == 1, nzchar(base_path))\n  stopifnot(is.character(project_name), length(project_name) == 1, nzchar(project_name))\n\n  # Normalize inputs\n  base_path &lt;- normalizePath(base_path, winslash = \"/\", mustWork = FALSE)\n\n  # Basic name safety (avoid characters that are awkward on Windows/macOS/Linux)\n  if (grepl(\"[/\\\\\\\\:*?\\\"&lt;&gt;|]\", project_name)) {\n    stop(\"project_name contains invalid path characters. Use a simple folder name.\")\n  }\n\n  project_path &lt;- file.path(base_path, project_name)\n\n  if (dir.exists(project_path)) {\n    stop(\"Target project directory already exists: \", project_path)\n  }\n\n  # Create main directory\n  ok &lt;- dir.create(project_path, recursive = TRUE, showWarnings = FALSE)\n  if (!ok || !dir.exists(project_path)) {\n    stop(\"Failed to create project directory: \", project_path)\n  }\n\n  # Create subdirectories\n  subdirs &lt;- c(\"analysis\", \"source\", \"data\", \"results\", \"literature\")\n  for (d in subdirs) {\n    dir.create(file.path(project_path, d), showWarnings = FALSE)\n  }\n\n  # Create .Rproj file\n  rproj_path &lt;- file.path(project_path, paste0(project_name, \".Rproj\"))\n  rproj_contents &lt;- c(\n    \"Version: 1.0\",\n    \"\",\n    \"RestoreWorkspace: No\",\n    \"SaveWorkspace: No\",\n    \"AlwaysSaveHistory: Default\",\n    \"\",\n    \"EnableCodeIndexing: Yes\",\n    \"UseSpacesForTab: Yes\",\n    \"NumSpacesForTab: 2\",\n    \"Encoding: UTF-8\",\n    \"\",\n    \"RnwWeave: Sweave\",\n    \"LaTeX: pdfLaTeX\"\n  )\n  writeLines(rproj_contents, con = rproj_path, useBytes = TRUE)\n\n  # Create README.md\n  readme_path &lt;- file.path(project_path, \"README.md\")\n  readme_contents &lt;- c(\n    paste0(\"# \", project_name),\n    \"\",\n    \"## Overview\",\n    \"Describe the purpose of this project.\",\n    \"\",\n    \"## Structure\",\n    \"- `analysis/` - analysis scripts and notebooks\",\n    \"- `source/` - reusable functions and modules\",\n    \"- `data/` - raw and intermediate data (consider a data management policy)\",\n    \"- `results/` - figures, tables, and outputs\",\n    \"- `literature/` - papers, notes, and references\",\n    \"\",\n    \"## Reproducibility\",\n    \"- Record package versions (e.g., `renv::init()`) as needed.\"\n  )\n  writeLines(readme_contents, con = readme_path, useBytes = TRUE)\n\n  # Initialize git repo (optional)\n  if (isTRUE(git)) {\n    git_available &lt;- nzchar(Sys.which(\"git\"))\n    if (!git_available) {\n      warning(\"git=TRUE but Git executable not found on PATH; skipping git init.\")\n    } else {\n      old_wd &lt;- getwd()\n      on.exit(setwd(old_wd), add = TRUE)\n      setwd(project_path)\n\n      # Initialize repository\n      system2(\"git\", c(\"init\"), stdout = TRUE, stderr = TRUE)\n\n      # Optional: create a minimal .gitignore tailored to typical R projects\n      gitignore_path &lt;- file.path(project_path, \".gitignore\")\n      gitignore_contents &lt;- c(\n        \".Rhistory\",\n        \".RData\",\n        \".Ruserdata\",\n        \".DS_Store\",\n        \"Thumbs.db\",\n        \"results/\",\n        \"data/\"\n      )\n      writeLines(gitignore_contents, con = gitignore_path, useBytes = TRUE)\n    }\n  }\n\n  # Optionally open the project in RStudio if available\n  if (isTRUE(open_rproj)) {\n    if (interactive() && nzchar(Sys.which(\"rstudio\"))) {\n      system2(\"rstudio\", rproj_path, wait = FALSE)\n    } else if (interactive()) {\n      message(\"open_rproj=TRUE but could not find 'rstudio' on PATH; created: \", rproj_path)\n    }\n  }\n\n  invisible(list(\n    project_path = project_path,\n    subdirs = file.path(project_path, subdirs),\n    rproj = rproj_path,\n    readme = readme_path,\n    git_initialized = isTRUE(git) && nzchar(Sys.which(\"git\"))\n  ))\n}\n\n\n\nThe CDC has over 1300 open-source datasets available at data.cdc.gov.\n\nTopic areas include injury & violence, vaccination, smoking,pregnancy, chronic disease, and disease surveillance\nGreat source of Covid surveillance data\ndata.gov hosts additional 250K+ datasets\n\nThe Covid Wastewater dataset comes from the National Wastewater Surveillance System(NWSS) Public SARS-CoV-2 Concentration in Wastewater Data.\n\nContains SARS-CoV-2 concentration at different sampling locations across the U.S.\nUpdate Daily\n\nThere are two available datasets:\n\nLongitudinal data, which has four columns and provides concentrations over time\nCross-sectional data, which includes current concentration and other summaries, as well as information about state, county (16 total columns)\n\nOur goal is to produce an end-to-end reproducible workflow with this data. We will do the following:\n\nDownload the data directly into R by interacting with the CDC API.\nClean the data: Longitudinal data contains concentrations over time,and cross-sectional data contains information about county each data collection site is located in. We will merge these two datasets and subset to collection sites in Georgia only.\nAnalyze data.\nVisualize data.\n\nPull these steps together into a documented reproducible report.\n\n\nI’ve done most of these steps for us already by creating an example project folder. Download it here.\n\nDownload and unzip this folder\nCheck out the files in the source subfolder. What are each of these doing?\nBuild a final_report Quarto or R Markdown document that calls each of the steps of the data analysis, and explains what is being done at each step.\nAs you make changes to the project, commit changes using git.\nFeel free to add some of your own visualizations.\n\n\n\n\n\nPush your finished project to GitHub\nClone one of your classmate’s repos and try to run their final report document. Was it fully reproducible?"
  },
  {
    "objectID": "content_repro.html#overview",
    "href": "content_repro.html#overview",
    "title": "A Crash Course in Reproducible Computing",
    "section": "",
    "text": "In this, we will cover basic topics in reproducible computing, including coding style, project organization, and git/GitHub.\n\nSlide Deck: project organizationSlide Deck: git/GithubLab: projectrLab: CDC open data\n\n\n\nCrash course on reproducible computing in R\nDownload slides (PDF)\n\n\n\n\nCrash course on reproducible computing in R\nDownload slides (PDF)\n\n\n\nI asked ChatGPT to write me some code for creating a reproducible file structure for a new project. The prompt I used is below:\n\nCan you write me an R function that will take in a filepath, and name for a new directlry then create a new directory with that same that includes subfolders called “analysis”, “source”, “data”, “results”, and “literature”, and also contains an initialized .git repo, a .Rproj file with the same name as the new directory in the root, and a README.md file?\n\nBelow is the code it wrote me. What is it doing? Modify it to suit your own preferences, and see if it works!\n\nAlso, we just spent a while talking about coding practices. What do you like about this code? What do you dislike?\n\n\ncreate_r_project_skeleton &lt;- function(base_path,\n                                      project_name,\n                                      open_rproj = FALSE,\n                                      git = TRUE) {\n  stopifnot(is.character(base_path), length(base_path) == 1, nzchar(base_path))\n  stopifnot(is.character(project_name), length(project_name) == 1, nzchar(project_name))\n\n  # Normalize inputs\n  base_path &lt;- normalizePath(base_path, winslash = \"/\", mustWork = FALSE)\n\n  # Basic name safety (avoid characters that are awkward on Windows/macOS/Linux)\n  if (grepl(\"[/\\\\\\\\:*?\\\"&lt;&gt;|]\", project_name)) {\n    stop(\"project_name contains invalid path characters. Use a simple folder name.\")\n  }\n\n  project_path &lt;- file.path(base_path, project_name)\n\n  if (dir.exists(project_path)) {\n    stop(\"Target project directory already exists: \", project_path)\n  }\n\n  # Create main directory\n  ok &lt;- dir.create(project_path, recursive = TRUE, showWarnings = FALSE)\n  if (!ok || !dir.exists(project_path)) {\n    stop(\"Failed to create project directory: \", project_path)\n  }\n\n  # Create subdirectories\n  subdirs &lt;- c(\"analysis\", \"source\", \"data\", \"results\", \"literature\")\n  for (d in subdirs) {\n    dir.create(file.path(project_path, d), showWarnings = FALSE)\n  }\n\n  # Create .Rproj file\n  rproj_path &lt;- file.path(project_path, paste0(project_name, \".Rproj\"))\n  rproj_contents &lt;- c(\n    \"Version: 1.0\",\n    \"\",\n    \"RestoreWorkspace: No\",\n    \"SaveWorkspace: No\",\n    \"AlwaysSaveHistory: Default\",\n    \"\",\n    \"EnableCodeIndexing: Yes\",\n    \"UseSpacesForTab: Yes\",\n    \"NumSpacesForTab: 2\",\n    \"Encoding: UTF-8\",\n    \"\",\n    \"RnwWeave: Sweave\",\n    \"LaTeX: pdfLaTeX\"\n  )\n  writeLines(rproj_contents, con = rproj_path, useBytes = TRUE)\n\n  # Create README.md\n  readme_path &lt;- file.path(project_path, \"README.md\")\n  readme_contents &lt;- c(\n    paste0(\"# \", project_name),\n    \"\",\n    \"## Overview\",\n    \"Describe the purpose of this project.\",\n    \"\",\n    \"## Structure\",\n    \"- `analysis/` - analysis scripts and notebooks\",\n    \"- `source/` - reusable functions and modules\",\n    \"- `data/` - raw and intermediate data (consider a data management policy)\",\n    \"- `results/` - figures, tables, and outputs\",\n    \"- `literature/` - papers, notes, and references\",\n    \"\",\n    \"## Reproducibility\",\n    \"- Record package versions (e.g., `renv::init()`) as needed.\"\n  )\n  writeLines(readme_contents, con = readme_path, useBytes = TRUE)\n\n  # Initialize git repo (optional)\n  if (isTRUE(git)) {\n    git_available &lt;- nzchar(Sys.which(\"git\"))\n    if (!git_available) {\n      warning(\"git=TRUE but Git executable not found on PATH; skipping git init.\")\n    } else {\n      old_wd &lt;- getwd()\n      on.exit(setwd(old_wd), add = TRUE)\n      setwd(project_path)\n\n      # Initialize repository\n      system2(\"git\", c(\"init\"), stdout = TRUE, stderr = TRUE)\n\n      # Optional: create a minimal .gitignore tailored to typical R projects\n      gitignore_path &lt;- file.path(project_path, \".gitignore\")\n      gitignore_contents &lt;- c(\n        \".Rhistory\",\n        \".RData\",\n        \".Ruserdata\",\n        \".DS_Store\",\n        \"Thumbs.db\",\n        \"results/\",\n        \"data/\"\n      )\n      writeLines(gitignore_contents, con = gitignore_path, useBytes = TRUE)\n    }\n  }\n\n  # Optionally open the project in RStudio if available\n  if (isTRUE(open_rproj)) {\n    if (interactive() && nzchar(Sys.which(\"rstudio\"))) {\n      system2(\"rstudio\", rproj_path, wait = FALSE)\n    } else if (interactive()) {\n      message(\"open_rproj=TRUE but could not find 'rstudio' on PATH; created: \", rproj_path)\n    }\n  }\n\n  invisible(list(\n    project_path = project_path,\n    subdirs = file.path(project_path, subdirs),\n    rproj = rproj_path,\n    readme = readme_path,\n    git_initialized = isTRUE(git) && nzchar(Sys.which(\"git\"))\n  ))\n}\n\n\n\nThe CDC has over 1300 open-source datasets available at data.cdc.gov.\n\nTopic areas include injury & violence, vaccination, smoking,pregnancy, chronic disease, and disease surveillance\nGreat source of Covid surveillance data\ndata.gov hosts additional 250K+ datasets\n\nThe Covid Wastewater dataset comes from the National Wastewater Surveillance System(NWSS) Public SARS-CoV-2 Concentration in Wastewater Data.\n\nContains SARS-CoV-2 concentration at different sampling locations across the U.S.\nUpdate Daily\n\nThere are two available datasets:\n\nLongitudinal data, which has four columns and provides concentrations over time\nCross-sectional data, which includes current concentration and other summaries, as well as information about state, county (16 total columns)\n\nOur goal is to produce an end-to-end reproducible workflow with this data. We will do the following:\n\nDownload the data directly into R by interacting with the CDC API.\nClean the data: Longitudinal data contains concentrations over time,and cross-sectional data contains information about county each data collection site is located in. We will merge these two datasets and subset to collection sites in Georgia only.\nAnalyze data.\nVisualize data.\n\nPull these steps together into a documented reproducible report.\n\n\nI’ve done most of these steps for us already by creating an example project folder. Download it here.\n\nDownload and unzip this folder\nCheck out the files in the source subfolder. What are each of these doing?\nBuild a final_report Quarto or R Markdown document that calls each of the steps of the data analysis, and explains what is being done at each step.\nAs you make changes to the project, commit changes using git.\nFeel free to add some of your own visualizations.\n\n\n\n\n\nPush your finished project to GitHub\nClone one of your classmate’s repos and try to run their final report document. Was it fully reproducible?"
  },
  {
    "objectID": "topic_R_packages.html",
    "href": "topic_R_packages.html",
    "title": "Building R Packages",
    "section": "",
    "text": "In progress."
  },
  {
    "objectID": "topic_reproducible_computing.html",
    "href": "topic_reproducible_computing.html",
    "title": "Reproducible Computing",
    "section": "",
    "text": "Covers reproducible computing in R, briefly GitHub, and some best practices for efficient coding in R\n\nReproducible computing, Project organization/Version control\nReproducible computing, Vectorization, code profiling, and parallelization\n\nThis paper on good enough practices for scientific computing gives an idea of what we want to achieve in this course, and why we want to achieve it.\nAlso, check out this editorial I co-wrote as one of the Associate Editor’s for Reproducibility at JASA. It describes the JASA reproducibility process."
  },
  {
    "objectID": "labs/lab_optimization_solutions.html",
    "href": "labs/lab_optimization_solutions.html",
    "title": "Lab: a crash course in reproducibility",
    "section": "",
    "text": "Load your libraries here. I find it to be best practice to load libraries at the beginning of a document. Why?"
  },
  {
    "objectID": "labs/lab_optimization_solutions.html#exercise-1",
    "href": "labs/lab_optimization_solutions.html#exercise-1",
    "title": "Lab: a crash course in reproducibility",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nTry out the steepest descent algorithm with different x0 and alpha values\n\nFor each x0 and alpha value, plot the evolution of \\(x\\) with each iteration\nFor each x0 and alpha value, plot the evolution of \\(f'(x)\\) with each iteration\n\nWhat is the solution?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[1] 8.334836\n\n\n[1] 244\n\n\n[1] TRUE"
  },
  {
    "objectID": "labs/lab_optimization_solutions.html#exercise-2",
    "href": "labs/lab_optimization_solutions.html#exercise-2",
    "title": "Lab: a crash course in reproducibility",
    "section": "Exercise 2",
    "text": "Exercise 2\nModify the steepest_descent() function above to use Newtons method for adjusting step size and call this new function newton().\n\nHow does newton() compare with steepest_descent() in terms of number of iterations?\nHow does newton() compare with steepest_descent() in terms of computation time?\n\n\n\n[1] 8.334836\n\n\n\n\n\n\n\n\n\n[1] 8.334836\n\n\nLet’s also plot the hessian"
  },
  {
    "objectID": "content_optimization.html",
    "href": "content_optimization.html",
    "title": "Convex optimization",
    "section": "",
    "text": "In this, we will introduce optimization and methods for gradient descent.\n\nSlide Deck: Introduction to optimizationSlide Deck: Gradient methodsLab: Introduction to optimizationLab: Gradient descent\n\n\n\nIntro optimization\nDownload slides (PDF)\n\n\n\n\nGradient Methods\nDownload slides (PDF)\n\n\n\n\n\nFor simplicity, we’ll focus on a one-dimensional example.\n\\[\nf(x) = (x-50)^2 + e^x/50, \\quad f'(x) = 2x - 100 + e^x/50 = 0\n\\]\nThe R function below, steepest_descent(), implements this algorithm for \\(f(x)\\).\n\n\n\nTry out the steepest descent algorithm with different x0 and alpha values\n\nFor each x0 and alpha value, plot the evolution of \\(x\\) with each iteration\nFor each x0 and alpha value, plot the evolution of \\(f'(x)\\) with each iteration\n\nWhat is the solution?\n\nNewton’s method\nWe’ll use the same example as from the steepest descent algorithm.\n\\[f(x) = (x-50)^2 + e^x/50, \\quad f'(x) = 2x - 100 + e^x/50 = 0\\]\n\n\\(f''(x) = 2 + e^x/50\\)\n\n\n\n\nModify the steepest_descent() function above to use Newtons method for adjusting step size and call this new function newton().\n\nHow does newton() compare with steepest_descent() in terms of number of iterations?\nHow does newton() compare with steepest_descent() in terms of computation time?\n\n\n\n\n\n\n\n\n\\[\\log(E[Y_i|X_i]) = X_i^T\\beta \\]\n\n\\(Y_i \\sim Poisson(\\mu_i)\\)\n\\(Var(\\mu_i) = \\mu_i\\)\n\\(g'(\\mu_i) = \\frac{1}{\\mu_i}\\)\n\n\\[l(\\beta) = \\sum_i \\left( y_iX_i^T\\beta-e^{X_i^T\\beta}-\\log y_i!\\right)\\]\n\ngradient: \\(\\frac{\\partial l(\\beta)}{\\partial \\beta} = \\sum_i(Y_i - e^{X_i^T\\beta})X_i\\)\nHessian: \\(\\frac{\\partial^2 l(\\beta)}{\\partial \\beta^2} = -\\sum_i e^{X_i^T\\beta} X_i^TX_i\\)\n\n\n\nThe function newton() below performs Newton’s method for the lab example from earlier. Make a new function, newton_poisson(), to find MLE estimates for \\(\\beta\\) in Poisson regression. Use a simulated dataset with the following parameters:\nSimulation study specification:\n\nsimulate from the model \\(log(E(Y_i = 1|X_i)) = \\beta_0 + \\beta_1X_i\\)\n\n\\(\\beta_0 = 1\\)\n\\(\\beta_1 = 0.3\\)\n\\(X_i \\sim N(0, 1)\\)\n\\(n = 100\\)\n\\(nsim = 1\\)\n\n\nTry a couple starting parameters for beta, including both good (close to the ground truth) and bad values.\n\nnewton = function(x0, tol = 1e-6, max_iter = 100) {\n\n  x = x0\n  \n  x_history = gradient_vec = hessian_vec = rep(NA, length.out = max_iter)\n  for (iter in 1:max_iter) {\n    \n    # store results\n    x_history[iter] = x\n    \n    \n    # Compute the gradient\n    gradient = 2 * x-100 + exp(x)/50\n    hessian = 2 + exp(x)/50\n    gradient_vec[iter] = gradient\n    hessian_vec[iter] = hessian\n    \n    \n    # Check stopping criterion\n    if(abs(gradient) &lt; tol){\n      message(\"Converged in \", iter, \" iterations.\\n\")\n      break\n    }\n    \n    # Update the solution\n    x = x - gradient/hessian\n\n  }\n  \n  return(list(solution = x, \n              x_history = x_history,\n              gradient = gradient_vec,\n              hessian = hessian_vec,\n              converged = (iter &lt; max_iter),\n              niter = iter))\n}\n\n\n# x is a matric of the covariate values\n# beta0 is a vector of the initial values for beta- what are good starting values?\nnewton_poisson = function(beta0 = c(0,0), \n                          x,\n                          tol = 1e-6, max_iter = 100) {\n\n  beta_cur = beta0\n  beta_history = gradient_vec = matrix(NA, nrow = max_iter, \n                                       ncol = length(beta0))\n  for (iter in 1:max_iter) {\n    \n    # store results\n    beta_history[iter,] = beta_cur\n    \n    # Compute the gradient and hessian\n    gradient = as.numeric(t(y-exp(x %*% beta_cur))%*% x)\n    \n    hessian_ls = as.list(rep(NA, length.out = length(y)))\n    for(i in 1:length(y)){\n      hessian_ls[[i]] = as.numeric(exp(x[i,]%*%beta_cur)) * tcrossprod(x[i,], x[i,])\n    }\n    \n    hessian &lt;- -1 * Reduce(\"+\", hessian_ls)\n    \n    gradient_vec[iter,] = gradient\n    \n    # Check stopping criterion\n    if(abs(sum(gradient)) &lt; tol){\n      message(\"Converged in \", iter, \" iterations.\\n\")\n      break\n    }\n    \n    # Update the solution\n    beta_cur = beta_cur - solve(hessian) %*% gradient\n  }\n  \n  # calculate standard errors\n  information = -hessian\n  se = sqrt(solve(information))\n  \n  return(list(solution = beta_cur, \n              beta_history = beta_history,\n              gradient = gradient_vec,\n              se = se,\n              information = information, # final hessian matrix\n              converged = (iter &lt; max_iter),\n              niter = iter))\n}\n\n\nset.seed(343243)\nn = 100\nbeta0 = 1\nbeta1 = 2\nx = rnorm(n)\nxmat = cbind(1, x)\nlambda = exp(beta0 + beta1 * x)\ny = rpois(n, lambda)\n\nbeta_init = c(-5,20)\n\nmy_mod = newton_poisson(beta_init, x = xmat)\n\nConverged in 45 iterations.\n\n\nWarning in sqrt(solve(information)): NaNs produced\n\nmy_mod$solution\n\n         [,1]\n[1,] 1.033739\n[2,] 1.972184\n\nmod = glm(y ~x, family = poisson)\nsummary(mod)$coefficients\n\n            Estimate Std. Error  z value     Pr(&gt;|z|)\n(Intercept) 1.033739 0.05949264 17.37592 1.255702e-67\nx           1.972184 0.03038499 64.90652 0.000000e+00\n\n\n\n\n\nModify your newton_poisson() function to return a 95% confidence interval for \\(\\beta\\). How do your results compare to glm()?\n\n\n[1] 0.05949291 0.03038509\n\n\n\n\n\n\nThis is the beginning of HW 2.\nFor a given subject in a study, we are interested in modeling \\(\\pi_i = P(Y_i = 1|X_i = x_i)\\), where \\(Y_i \\in \\{0, 1\\}\\). The logistic regression model takes the form\n\n\\[\\text{logit}(\\pi_i) = \\log \\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = \\log\\left({\\frac{P(Y_i = 1|X_i)}{1-P(Y_i = 1|X_i)}}\\right) = \\beta_0 + \\beta_1X_{1i} + \\beta_2X_{2i} + \\ldots + \\beta_pX_{pi}\\]\n\n\\(Y_1, Y_2,\\ldots, Y_n \\sim Bernoulli(\\pi)\\)\nPDF is \\(f(y_i; \\pi) = \\pi^{y_i}(1-\\pi)^{1-y_i}\\)\n\n\n\n\nDerive likelihood, gradient, and Hessian for logistic regression for an arbitrary number of predictors \\(p\\)\nWhat is the Newton’s method update for \\(\\beta\\) for logistic regression?\nIs logistic regression a convex optimization problem? Why or why not?"
  },
  {
    "objectID": "content_optimization.html#overview",
    "href": "content_optimization.html#overview",
    "title": "Convex optimization",
    "section": "",
    "text": "In this, we will introduce optimization and methods for gradient descent.\n\nSlide Deck: Introduction to optimizationSlide Deck: Gradient methodsLab: Introduction to optimizationLab: Gradient descent\n\n\n\nIntro optimization\nDownload slides (PDF)\n\n\n\n\nGradient Methods\nDownload slides (PDF)\n\n\n\n\n\nFor simplicity, we’ll focus on a one-dimensional example.\n\\[\nf(x) = (x-50)^2 + e^x/50, \\quad f'(x) = 2x - 100 + e^x/50 = 0\n\\]\nThe R function below, steepest_descent(), implements this algorithm for \\(f(x)\\).\n\n\n\nTry out the steepest descent algorithm with different x0 and alpha values\n\nFor each x0 and alpha value, plot the evolution of \\(x\\) with each iteration\nFor each x0 and alpha value, plot the evolution of \\(f'(x)\\) with each iteration\n\nWhat is the solution?\n\nNewton’s method\nWe’ll use the same example as from the steepest descent algorithm.\n\\[f(x) = (x-50)^2 + e^x/50, \\quad f'(x) = 2x - 100 + e^x/50 = 0\\]\n\n\\(f''(x) = 2 + e^x/50\\)\n\n\n\n\nModify the steepest_descent() function above to use Newtons method for adjusting step size and call this new function newton().\n\nHow does newton() compare with steepest_descent() in terms of number of iterations?\nHow does newton() compare with steepest_descent() in terms of computation time?\n\n\n\n\n\n\n\n\n\\[\\log(E[Y_i|X_i]) = X_i^T\\beta \\]\n\n\\(Y_i \\sim Poisson(\\mu_i)\\)\n\\(Var(\\mu_i) = \\mu_i\\)\n\\(g'(\\mu_i) = \\frac{1}{\\mu_i}\\)\n\n\\[l(\\beta) = \\sum_i \\left( y_iX_i^T\\beta-e^{X_i^T\\beta}-\\log y_i!\\right)\\]\n\ngradient: \\(\\frac{\\partial l(\\beta)}{\\partial \\beta} = \\sum_i(Y_i - e^{X_i^T\\beta})X_i\\)\nHessian: \\(\\frac{\\partial^2 l(\\beta)}{\\partial \\beta^2} = -\\sum_i e^{X_i^T\\beta} X_i^TX_i\\)\n\n\n\nThe function newton() below performs Newton’s method for the lab example from earlier. Make a new function, newton_poisson(), to find MLE estimates for \\(\\beta\\) in Poisson regression. Use a simulated dataset with the following parameters:\nSimulation study specification:\n\nsimulate from the model \\(log(E(Y_i = 1|X_i)) = \\beta_0 + \\beta_1X_i\\)\n\n\\(\\beta_0 = 1\\)\n\\(\\beta_1 = 0.3\\)\n\\(X_i \\sim N(0, 1)\\)\n\\(n = 100\\)\n\\(nsim = 1\\)\n\n\nTry a couple starting parameters for beta, including both good (close to the ground truth) and bad values.\n\nnewton = function(x0, tol = 1e-6, max_iter = 100) {\n\n  x = x0\n  \n  x_history = gradient_vec = hessian_vec = rep(NA, length.out = max_iter)\n  for (iter in 1:max_iter) {\n    \n    # store results\n    x_history[iter] = x\n    \n    \n    # Compute the gradient\n    gradient = 2 * x-100 + exp(x)/50\n    hessian = 2 + exp(x)/50\n    gradient_vec[iter] = gradient\n    hessian_vec[iter] = hessian\n    \n    \n    # Check stopping criterion\n    if(abs(gradient) &lt; tol){\n      message(\"Converged in \", iter, \" iterations.\\n\")\n      break\n    }\n    \n    # Update the solution\n    x = x - gradient/hessian\n\n  }\n  \n  return(list(solution = x, \n              x_history = x_history,\n              gradient = gradient_vec,\n              hessian = hessian_vec,\n              converged = (iter &lt; max_iter),\n              niter = iter))\n}\n\n\n# x is a matric of the covariate values\n# beta0 is a vector of the initial values for beta- what are good starting values?\nnewton_poisson = function(beta0 = c(0,0), \n                          x,\n                          tol = 1e-6, max_iter = 100) {\n\n  beta_cur = beta0\n  beta_history = gradient_vec = matrix(NA, nrow = max_iter, \n                                       ncol = length(beta0))\n  for (iter in 1:max_iter) {\n    \n    # store results\n    beta_history[iter,] = beta_cur\n    \n    # Compute the gradient and hessian\n    gradient = as.numeric(t(y-exp(x %*% beta_cur))%*% x)\n    \n    hessian_ls = as.list(rep(NA, length.out = length(y)))\n    for(i in 1:length(y)){\n      hessian_ls[[i]] = as.numeric(exp(x[i,]%*%beta_cur)) * tcrossprod(x[i,], x[i,])\n    }\n    \n    hessian &lt;- -1 * Reduce(\"+\", hessian_ls)\n    \n    gradient_vec[iter,] = gradient\n    \n    # Check stopping criterion\n    if(abs(sum(gradient)) &lt; tol){\n      message(\"Converged in \", iter, \" iterations.\\n\")\n      break\n    }\n    \n    # Update the solution\n    beta_cur = beta_cur - solve(hessian) %*% gradient\n  }\n  \n  # calculate standard errors\n  information = -hessian\n  se = sqrt(solve(information))\n  \n  return(list(solution = beta_cur, \n              beta_history = beta_history,\n              gradient = gradient_vec,\n              se = se,\n              information = information, # final hessian matrix\n              converged = (iter &lt; max_iter),\n              niter = iter))\n}\n\n\nset.seed(343243)\nn = 100\nbeta0 = 1\nbeta1 = 2\nx = rnorm(n)\nxmat = cbind(1, x)\nlambda = exp(beta0 + beta1 * x)\ny = rpois(n, lambda)\n\nbeta_init = c(-5,20)\n\nmy_mod = newton_poisson(beta_init, x = xmat)\n\nConverged in 45 iterations.\n\n\nWarning in sqrt(solve(information)): NaNs produced\n\nmy_mod$solution\n\n         [,1]\n[1,] 1.033739\n[2,] 1.972184\n\nmod = glm(y ~x, family = poisson)\nsummary(mod)$coefficients\n\n            Estimate Std. Error  z value     Pr(&gt;|z|)\n(Intercept) 1.033739 0.05949264 17.37592 1.255702e-67\nx           1.972184 0.03038499 64.90652 0.000000e+00\n\n\n\n\n\nModify your newton_poisson() function to return a 95% confidence interval for \\(\\beta\\). How do your results compare to glm()?\n\n\n[1] 0.05949291 0.03038509\n\n\n\n\n\n\nThis is the beginning of HW 2.\nFor a given subject in a study, we are interested in modeling \\(\\pi_i = P(Y_i = 1|X_i = x_i)\\), where \\(Y_i \\in \\{0, 1\\}\\). The logistic regression model takes the form\n\n\\[\\text{logit}(\\pi_i) = \\log \\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = \\log\\left({\\frac{P(Y_i = 1|X_i)}{1-P(Y_i = 1|X_i)}}\\right) = \\beta_0 + \\beta_1X_{1i} + \\beta_2X_{2i} + \\ldots + \\beta_pX_{pi}\\]\n\n\\(Y_1, Y_2,\\ldots, Y_n \\sim Bernoulli(\\pi)\\)\nPDF is \\(f(y_i; \\pi) = \\pi^{y_i}(1-\\pi)^{1-y_i}\\)\n\n\n\n\nDerive likelihood, gradient, and Hessian for logistic regression for an arbitrary number of predictors \\(p\\)\nWhat is the Newton’s method update for \\(\\beta\\) for logistic regression?\nIs logistic regression a convex optimization problem? Why or why not?"
  },
  {
    "objectID": "topic_cloud_computing.html",
    "href": "topic_cloud_computing.html",
    "title": "Cloud Computing",
    "section": "",
    "text": "In progress."
  },
  {
    "objectID": "topic_simulation.html",
    "href": "topic_simulation.html",
    "title": "Simulation and Resampling",
    "section": "",
    "text": "Covers best practices for simulation studies in the first lecture, then bootstrap and permutation tests in the second lecture\n\nSimulation studies/Resampling methods\nParallelization and other speedup tricks\n\nA couple of papers I highly recommend reading on these topics are:\n\nUsing simulation studies to evaluate statistical methods\nBootstrap"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BIOS 731: Advanced Statistical Computing",
    "section": "",
    "text": "This course is being offered in the Spring of 2026 through the Biostatistics and Informatics Department at the Emory University Rollins School of Public Health.\n\nInstructor: Julia Wrobel"
  },
  {
    "objectID": "homework/topic_reproducible_computing/HW_reproducibility.html",
    "href": "homework/topic_reproducible_computing/HW_reproducibility.html",
    "title": "Homework 1: Reproducible Computing",
    "section": "",
    "text": "This assignment reinforces ideas in Module 1: Reproducible Computing in R. We focus specifically on project organization and GitHub."
  },
  {
    "objectID": "homework/topic_reproducible_computing/HW_reproducibility.html#context",
    "href": "homework/topic_reproducible_computing/HW_reproducibility.html#context",
    "title": "Homework 1: Reproducible Computing",
    "section": "",
    "text": "This assignment reinforces ideas in Module 1: Reproducible Computing in R. We focus specifically on project organization and GitHub."
  },
  {
    "objectID": "homework/topic_reproducible_computing/HW_reproducibility.html#due-date-and-submission",
    "href": "homework/topic_reproducible_computing/HW_reproducibility.html#due-date-and-submission",
    "title": "Homework 1: Reproducible Computing",
    "section": "Due date and submission",
    "text": "Due date and submission\nPlease submit (via Canvas) the web address of the GitHub repo containing your work for this assignment; git commits after the due date will cause the assignment to be considered late.\nR Markdown or Quarto documents included as part of your solutions must not install packages, and should only load the packages necessary for your submission to knit."
  },
  {
    "objectID": "homework/topic_reproducible_computing/HW_reproducibility.html#points",
    "href": "homework/topic_reproducible_computing/HW_reproducibility.html#points",
    "title": "Homework 1: Reproducible Computing",
    "section": "Points",
    "text": "Points\n\n\n\n\n\nProblem\nPoints\n\n\n\n\nProblem 0\n20\n\n\nProblem 1.1\n10\n\n\nProblem 1.2\n5\n\n\nProblem 1.3\n20\n\n\nProblem 1.4\n30\n\n\nProblem 1.5\n15"
  },
  {
    "objectID": "homework/topic_reproducible_computing/HW_reproducibility.html#problem-1",
    "href": "homework/topic_reproducible_computing/HW_reproducibility.html#problem-1",
    "title": "Homework 1: Reproducible Computing",
    "section": "Problem 1",
    "text": "Problem 1\nThis “problem” focuses on structure of your submission, especially the use git and GitHub for reproducibility, R Projects to organize your work, R Markdown/Quarto to write reproducible reports, relative paths to load data from local files, and reasonable naming structures for your files.\nTo that end:\n\ncreate a public GitHub repo + local R Project; I suggest naming this repo / directory bios731_hw1_YourLastName (e.g. bios731_hw1_wrobel for Julia)\nSubmit your whole project folder to GitHub\nSubmit a PDF knitted from Rmd to Canvas. Your solutions to the problem here should be implemented in your .Rmd file, and your git commit history should reflect the process you used to solve these Problems.\n\n\nCreate a reproducible project, using the project structure learned in the project organization structure.\nPick a dataset and do a brief analysis with this dataset following structure from project organization. You may want to use a dataset from your own research, however your project will need to be fully reproducible and hosted publicly on GitHub, so please make sure your dataset can be uploaded to GH before you do so! There should be a data cleaning component, and modeling component, a data visualization component, and a final report.\nYour project should have a README that describes the dataset as well as the files within your project folder.\nPut your project in a public repository on GitHub, please use informative commit messages.\nYour final product should be fully reproducible. Your grade will depend on it. We should be able to clone your repo from GitHub and follow the readme to reproduce the workflow without changing any filepaths or any thing else!."
  },
  {
    "objectID": "homework/topic_reproducible_computing/HW_reproducibility.html#rubric",
    "href": "homework/topic_reproducible_computing/HW_reproducibility.html#rubric",
    "title": "Homework 1: Reproducible Computing",
    "section": "Rubric",
    "text": "Rubric\n\nNeed to have Rproject\nShould have informative commit messages\nShould have code that is self documenting\nShould have a README explaining the workflow\nIf code doesn’t knit because we need to install a library first, no points should be deducted; however libraries should be loaded at the beginning of the document and readme should include sessionInfo()"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "BIOS 731: Advanced Statistical Computing",
    "section": "",
    "text": "Department: Biostatistics and Bioinformatics\nCourse Number: BIOS 731\nSection Number: 1\nCredit Hours: 4\nSemester: Spring 2026\nClass Hours and Location:\nWednesday & Thursday, 10:00 AM – 11:50 AM, GCR P39\nInstructor:\nJulia Wrobel, PhD\nEmail:\njulia.wrobel@emory.edu\nSchool Address / Mailbox:\n1518 Clifton Rd, 1518-002-3AA\nOffice Hours:\nThursdays 1:00 PM- 2:00 PM\nGCR Room 210\nTeaching Assistant:\nWeijia Qian (weijia.qian@emory.edu)\nTA Office Hours: Tuesdays 11:00 AM - 12:00 PM GCR Room 369"
  },
  {
    "objectID": "syllabus.html#instructor-contact-information",
    "href": "syllabus.html#instructor-contact-information",
    "title": "BIOS 731: Advanced Statistical Computing",
    "section": "",
    "text": "Department: Biostatistics and Bioinformatics\nCourse Number: BIOS 731\nSection Number: 1\nCredit Hours: 4\nSemester: Spring 2026\nClass Hours and Location:\nWednesday & Thursday, 10:00 AM – 11:50 AM, GCR P39\nInstructor:\nJulia Wrobel, PhD\nEmail:\njulia.wrobel@emory.edu\nSchool Address / Mailbox:\n1518 Clifton Rd, 1518-002-3AA\nOffice Hours:\nThursdays 1:00 PM- 2:00 PM\nGCR Room 210\nTeaching Assistant:\nWeijia Qian (weijia.qian@emory.edu)\nTA Office Hours: Tuesdays 11:00 AM - 12:00 PM GCR Room 369"
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "BIOS 731: Advanced Statistical Computing",
    "section": "Course Description",
    "text": "Course Description\nThis course, designed for Ph.D. biostatistics students, dives into the methods and applications of essential statistical computing techniques. Students will achieve two key goals:\n1. Master the implementation of algorithms behind widely used statistical models\n2. Build fluency in reproducible statistical programming\nWith a focus on practical implementation, the course balances foundational theory with hands-on computational experience. Topics include random number generation, bootstrap methods, optimization techniques, Expectation-Maximization (EM), Minorization-Maximization (MM), and Markov chain Monte Carlo (MCMC). On the programming side, students will explore simulation design, cluster computing, code profiling, parallelization, and R package development.\nThis course requires a significant amount of programming. Class examples and homework assignments will be predominantly in R. Because R can be relatively slow, students will learn how to optimize R for computational efficiency through code profiling and parallelization, and how to implement faster C++ backends using Rcpp.\nFor standard algorithms such as Newton–Raphson, EM, iteratively reweighted least squares, and Gibbs sampling, homework assignments will require students to directly implement the algorithm rather than use existing software packages. For more advanced topics—including ADMM, variational inference, and deep learning—assignments will focus on reading and summarizing journal articles and performing analyses using existing software.\nThe final project allows students to apply tools learned in class to topics related to their dissertation research.\nPrerequisites: BIOS 707, BIOS 709, or permission of the instructor.\nThe course will make heavy use of matrix algebra, including vector and matrix derivatives, norms, eigenvalues and eigenvectors, and matrix inverses.\nR is required for homework assignments unless otherwise specified."
  },
  {
    "objectID": "syllabus.html#course-learning-objectives",
    "href": "syllabus.html#course-learning-objectives",
    "title": "BIOS 731: Advanced Statistical Computing",
    "section": "Course Learning Objectives",
    "text": "Course Learning Objectives\nUpon successful completion of the course, students should be able to:\n\nUnderstand the theoretical and computational foundations of algorithms covered in the course\n\nImplement algorithms using high-level programming languages\n\nApply methods to real-world data\n\nWrite efficient, reproducible R code locally and on computing clusters\n\n\nPhD Competency Assessed\n\nDevelop and assess new statistical methods\n\nHomework 1 involves designing and implementing a simulation study.\n\nConduct complex statistical analyses\n\nThe final project applies a recent computational method to a real dataset.\n\nConduct independent research in biostatistics\n\nThe final exam involves reading a research paper and implementing the proposed method."
  },
  {
    "objectID": "syllabus.html#evaluation",
    "href": "syllabus.html#evaluation",
    "title": "BIOS 731: Advanced Statistical Computing",
    "section": "Evaluation",
    "text": "Evaluation\nEvaluation will be based on the following components:\n\n\n\nAssessment\nPercentage\n\n\n\n\nHomework (7 assignments)\n50%\n\n\nFinal Project and Presentation\n30%\n\n\nDiscussion Board (4 posts)\n10%\n\n\nParticipation\n10%\n\n\n\n\nGrading Scale\n\n\n\nGrade\nPercentage\nPoints\n\n\n\n\nA\n93–100%\n4.0\n\n\nA−\n90–93%\n3.7\n\n\nB+\n87–90%\n3.3\n\n\nB\n83–87%\n3.0\n\n\nB−\n80–83%\n2.7\n\n\nC\n65–80%\n2.0\n\n\nF\n&lt;65%\n0.0"
  },
  {
    "objectID": "syllabus.html#homework-50",
    "href": "syllabus.html#homework-50",
    "title": "BIOS 731: Advanced Statistical Computing",
    "section": "Homework (50%)",
    "text": "Homework (50%)\nHomework must be neat, well organized, and typed. Raw computer output is not acceptable. Numerical output should be incorporated into text or tables, and plots must be clearly labeled.\nStudents may collaborate, but submitted work must be their own and not identical to others.\nLate assignments receive a maximum of half credit. Assignments more than three days late will not be graded."
  },
  {
    "objectID": "syllabus.html#participation-10",
    "href": "syllabus.html#participation-10",
    "title": "BIOS 731: Advanced Statistical Computing",
    "section": "Participation (10%)",
    "text": "Participation (10%)\nStudents are expected to attend class in person. Participation credit requires attendance and engagement in at least 20 lectures through asking or answering questions."
  },
  {
    "objectID": "syllabus.html#final-project-and-presentation-30",
    "href": "syllabus.html#final-project-and-presentation-30",
    "title": "BIOS 731: Advanced Statistical Computing",
    "section": "Final Project and Presentation (30%)",
    "text": "Final Project and Presentation (30%)\nStudents will select a computational method from the past five years, apply it to a dataset, and present results to the class.\n\n\n\nComponent\nWeight\n\n\n\n\nWritten report\n50%\n\n\nIn-class presentation\n50%"
  },
  {
    "objectID": "syllabus.html#discussion-board-10",
    "href": "syllabus.html#discussion-board-10",
    "title": "BIOS 731: Advanced Statistical Computing",
    "section": "Discussion Board (10%)",
    "text": "Discussion Board (10%)\nFour discussion posts based on readings and/or seminar lectures."
  },
  {
    "objectID": "syllabus.html#course-structure",
    "href": "syllabus.html#course-structure",
    "title": "BIOS 731: Advanced Statistical Computing",
    "section": "Course Structure",
    "text": "Course Structure\nThis course meets in person twice weekly. The first half of each class is lecture-based, and the second half focuses on problem-solving in small groups."
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "BIOS 731: Advanced Statistical Computing",
    "section": "Course Policies",
    "text": "Course Policies\n\nAttendance\nRegular attendance is expected. Classes will be recorded and posted on Canvas.\n\n\nReadings and Texts\nNo required textbook. Suggested references include:\n\nMatloff, The Art of R Programming\nWickham, Advanced R\nBoyd & Vandenberghe, Convex Optimization\nHastie et al., Statistical Learning with Sparsity\nHastie et al., The Elements of Statistical Learning\nGolub & Van Loan, Matrix Computations\n\n\n\nInclusivity\nThis course values diverse perspectives. Please share your preferred name and pronouns."
  },
  {
    "objectID": "syllabus.html#rsph-policies",
    "href": "syllabus.html#rsph-policies",
    "title": "BIOS 731: Advanced Statistical Computing",
    "section": "RSPH Policies",
    "text": "RSPH Policies\n\nAccessibility and Accommodations\nStudents requiring accommodations must register with the Office of Accessibility Services.\n\n\nHonor Code and Academic Integrity\nStudents are expected to uphold the Laney Graduate School Honor Code."
  },
  {
    "objectID": "syllabus.html#class-schedule-tentative",
    "href": "syllabus.html#class-schedule-tentative",
    "title": "BIOS 731: Advanced Statistical Computing",
    "section": "Class Schedule (Tentative)",
    "text": "Class Schedule (Tentative)\n\n\n\n\n\n\n\n\n\nDate\nModule\nTopic\nAssignment\n\n\n\n\n1/14\nReproducible Computing\nGit/GitHub, reproducible R\n—\n\n\n1/15\nReproducible Computing\nDebugging, profiling\n\n\n\n1/21\nSimulation & Resampling\nSimulation studies\nHW1 due\n\n\n1/22\nSimulation & Resampling\nBootstrap & permutation tests\n\n\n\n1/28\nReproducible Computing\nParallelization, parametric reports\n\n\n\n1/29\n—\nNo class\n\n\n\n2/4\nOptimization I\nIntroduction to optimization\n\n\n\n2/5\nOptimization I\nGradient methods, GLMs\n\n\n\n2/11\nOptimization I\nEM I: applications\nHW2 due\n\n\n2/18\nOptimization I\nEM II: theory\n\n\n\n2/19\nOptimization I\nMM algorithm\n\n\n\n2/25\nBayesian Computing\nNumerical integration & sampling\n\n\n\n2/26\nBayesian Computing\nIntroduction to MCMC\n\n\n\n3/4\nBayesian Computing\nMCMC II\nHW3 due\n\n\n3/5\nBayesian Computing\nVariational Bayes\nProject proposals due\n\n\n3/11\nSpring Break\nNo class\n\n\n\n3/12\nSpring Break\nNo class\n\n\n\n3/18\nENAR\nNo class\n\n\n\n3/19\nCloud Computing\nHPC usage (guest lecture)\nHW4 due\n\n\n3/25\nCloud Computing\nCluster project organization\n\n\n\n3/26\nR Packages\nPackage basics\nHW5 due\n\n\n4/1\nR Packages\nRcpp\n\n\n\n4/2\nOptimization II\nLP, quantile regression\nHW6 due\n\n\n4/8\nOptimization II\nQP, LASSO\n\n\n\n4/9\nOptimization II\nHMM and ADMM\n\n\n\n4/15\nOptimization II\nStochastic gradient descent\n\n\n\n4/16\nSpecial Topics\nTBD\nHW7 due\n\n\n4/22\nFinal Presentations\nFirst half\n\n\n\n4/23\nFinal Presentations\nSecond half\n\n\n\n5/1\nFinal Project Due"
  },
  {
    "objectID": "content_EM.html",
    "href": "content_EM.html",
    "title": "Optimization: EM and MM Algorithms",
    "section": "",
    "text": "In this, we will focus on the EM and MM algorithms.\n\nSlide Deck: Introduction to the Expectation-Maximization (EM) AlgorithmSlide Deck: EM TheorySlide Deck: MMLab: Introduction to optimizationLab: Gradient descent\n\n\n\nIntro EM\nDownload slides (PDF)\n\n\n\n\nEM Theory\nDownload slides (PDF)\n\n\n\n\n\n\n\n\nFor simplicity, we’ll focus on a one-dimensional example.\n\\[\nf(x) = (x-50)^2 + e^x/50, \\quad f'(x) = 2x - 100 + e^x/50 = 0\n\\]\nThe R function below, steepest_descent(), implements this algorithm for \\(f(x)\\).\n\n\n\nTry out the steepest descent algorithm with different x0 and alpha values\n\nFor each x0 and alpha value, plot the evolution of \\(x\\) with each iteration\nFor each x0 and alpha value, plot the evolution of \\(f'(x)\\) with each iteration\n\nWhat is the solution?\n\nNewton’s method\nWe’ll use the same example as from the steepest descent algorithm.\n\\[f(x) = (x-50)^2 + e^x/50, \\quad f'(x) = 2x - 100 + e^x/50 = 0\\]\n\n\\(f''(x) = 2 + e^x/50\\)\n\n\n\n\nModify the steepest_descent() function above to use Newtons method for adjusting step size and call this new function newton().\n\nHow does newton() compare with steepest_descent() in terms of number of iterations?\nHow does newton() compare with steepest_descent() in terms of computation time?\n\n\n\n\n\n\n\n\n\\[\\log(E[Y_i|X_i]) = X_i^T\\beta \\]\n\n\\(Y_i \\sim Poisson(\\mu_i)\\)\n\\(Var(\\mu_i) = \\mu_i\\)\n\\(g'(\\mu_i) = \\frac{1}{\\mu_i}\\)\n\n\\[l(\\beta) = \\sum_i \\left( y_iX_i^T\\beta-e^{X_i^T\\beta}-\\log y_i!\\right)\\]\n\ngradient: \\(\\frac{\\partial l(\\beta)}{\\partial \\beta} = \\sum_i(Y_i - e^{X_i^T\\beta})X_i\\)\nHessian: \\(\\frac{\\partial^2 l(\\beta)}{\\partial \\beta^2} = -\\sum_i e^{X_i^T\\beta} X_i^TX_i\\)\n\n\n\nThe function newton() below performs Newton’s method for the lab example from earlier. Make a new function, newton_poisson(), to find MLE estimates for \\(\\beta\\) in Poisson regression. Use a simulated dataset with the following parameters:\nSimulation study specification:\n\nsimulate from the model \\(log(E(Y_i = 1|X_i)) = \\beta_0 + \\beta_1X_i\\)\n\n\\(\\beta_0 = 1\\)\n\\(\\beta_1 = 0.3\\)\n\\(X_i \\sim N(0, 1)\\)\n\\(n = 100\\)\n\\(nsim = 1\\)\n\n\nTry a couple starting parameters for beta, including both good (close to the ground truth) and bad values.\n\nsimulate from the model \\(log(E(Y_i = 1|X_i)) = \\beta_0 + \\beta_1X_i\\)\n\n\\(\\beta_0 = 1\\)\n\\(\\beta_1 = 0.3\\)\n\\(X_i \\sim N(0, 1)\\)\n\\(n = 100\\)\n\\(nsim = 1\\)\n\n\n\n\nConverged in 21 iterations.\n\n\n           [,1]\n[1,]  1.3664363\n[2,] -0.0286162\n\n\n[1] 0.05113433 0.04826915\n\n\n\nCall:\nglm(formula = y ~ x, family = poisson)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.36644    0.05113  26.723   &lt;2e-16 ***\nx           -0.02862    0.04827  -0.593    0.553    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 93.889  on 99  degrees of freedom\nResidual deviance: 93.538  on 98  degrees of freedom\nAIC: 408.25\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\nModify your newton_poisson() function to return a 95% confidence interval for \\(\\beta\\). How do your results compare to glm()?\n\n\nfunction (x, y = NULL, na.rm = FALSE, use) \n{\n    if (missing(use)) \n        use &lt;- if (na.rm) \n            \"na.or.complete\"\n        else \"everything\"\n    na.method &lt;- pmatch(use, c(\"all.obs\", \"complete.obs\", \"pairwise.complete.obs\", \n        \"everything\", \"na.or.complete\"))\n    if (is.na(na.method)) \n        stop(\"invalid 'use' argument\")\n    if (is.data.frame(x)) \n        x &lt;- as.matrix(x)\n    else if (!is.null(x)) \n        stopifnot(is.atomic(x))\n    if (is.data.frame(y)) \n        y &lt;- as.matrix(y)\n    else if (!is.null(y)) \n        stopifnot(is.atomic(y))\n    .Call(C_cov, x, y, na.method, FALSE)\n}\n&lt;bytecode: 0x10ef753a8&gt;\n&lt;environment: namespace:stats&gt;\n\n\n\n\n\n\nThis is the beginning of HW 2.\nFor a given subject in a study, we are interested in modeling \\(\\pi_i = P(Y_i = 1|X_i = x_i)\\), where \\(Y_i \\in \\{0, 1\\}\\). The logistic regression model takes the form\n\n\\[\\text{logit}(\\pi_i) = \\log \\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = \\log\\left({\\frac{P(Y_i = 1|X_i)}{1-P(Y_i = 1|X_i)}}\\right) = \\beta_0 + \\beta_1X_{1i} + \\beta_2X_{2i} + \\ldots + \\beta_pX_{pi}\\]\n\n\\(Y_1, Y_2,\\ldots, Y_n \\sim Bernoulli(\\pi)\\)\nPDF is \\(f(y_i; \\pi) = \\pi^{y_i}(1-\\pi)^{1-y_i}\\)\n\n\n\n\nDerive likelihood, gradient, and Hessian for logistic regression for an arbitrary number of predictors \\(p\\)\nWhat is the Newton’s method update for \\(\\beta\\) for logistic regression?\nIs logistic regression a convex optimization problem? Why or why not?"
  },
  {
    "objectID": "content_EM.html#overview",
    "href": "content_EM.html#overview",
    "title": "Optimization: EM and MM Algorithms",
    "section": "",
    "text": "In this, we will focus on the EM and MM algorithms.\n\nSlide Deck: Introduction to the Expectation-Maximization (EM) AlgorithmSlide Deck: EM TheorySlide Deck: MMLab: Introduction to optimizationLab: Gradient descent\n\n\n\nIntro EM\nDownload slides (PDF)\n\n\n\n\nEM Theory\nDownload slides (PDF)\n\n\n\n\n\n\n\n\nFor simplicity, we’ll focus on a one-dimensional example.\n\\[\nf(x) = (x-50)^2 + e^x/50, \\quad f'(x) = 2x - 100 + e^x/50 = 0\n\\]\nThe R function below, steepest_descent(), implements this algorithm for \\(f(x)\\).\n\n\n\nTry out the steepest descent algorithm with different x0 and alpha values\n\nFor each x0 and alpha value, plot the evolution of \\(x\\) with each iteration\nFor each x0 and alpha value, plot the evolution of \\(f'(x)\\) with each iteration\n\nWhat is the solution?\n\nNewton’s method\nWe’ll use the same example as from the steepest descent algorithm.\n\\[f(x) = (x-50)^2 + e^x/50, \\quad f'(x) = 2x - 100 + e^x/50 = 0\\]\n\n\\(f''(x) = 2 + e^x/50\\)\n\n\n\n\nModify the steepest_descent() function above to use Newtons method for adjusting step size and call this new function newton().\n\nHow does newton() compare with steepest_descent() in terms of number of iterations?\nHow does newton() compare with steepest_descent() in terms of computation time?\n\n\n\n\n\n\n\n\n\\[\\log(E[Y_i|X_i]) = X_i^T\\beta \\]\n\n\\(Y_i \\sim Poisson(\\mu_i)\\)\n\\(Var(\\mu_i) = \\mu_i\\)\n\\(g'(\\mu_i) = \\frac{1}{\\mu_i}\\)\n\n\\[l(\\beta) = \\sum_i \\left( y_iX_i^T\\beta-e^{X_i^T\\beta}-\\log y_i!\\right)\\]\n\ngradient: \\(\\frac{\\partial l(\\beta)}{\\partial \\beta} = \\sum_i(Y_i - e^{X_i^T\\beta})X_i\\)\nHessian: \\(\\frac{\\partial^2 l(\\beta)}{\\partial \\beta^2} = -\\sum_i e^{X_i^T\\beta} X_i^TX_i\\)\n\n\n\nThe function newton() below performs Newton’s method for the lab example from earlier. Make a new function, newton_poisson(), to find MLE estimates for \\(\\beta\\) in Poisson regression. Use a simulated dataset with the following parameters:\nSimulation study specification:\n\nsimulate from the model \\(log(E(Y_i = 1|X_i)) = \\beta_0 + \\beta_1X_i\\)\n\n\\(\\beta_0 = 1\\)\n\\(\\beta_1 = 0.3\\)\n\\(X_i \\sim N(0, 1)\\)\n\\(n = 100\\)\n\\(nsim = 1\\)\n\n\nTry a couple starting parameters for beta, including both good (close to the ground truth) and bad values.\n\nsimulate from the model \\(log(E(Y_i = 1|X_i)) = \\beta_0 + \\beta_1X_i\\)\n\n\\(\\beta_0 = 1\\)\n\\(\\beta_1 = 0.3\\)\n\\(X_i \\sim N(0, 1)\\)\n\\(n = 100\\)\n\\(nsim = 1\\)\n\n\n\n\nConverged in 21 iterations.\n\n\n           [,1]\n[1,]  1.3664363\n[2,] -0.0286162\n\n\n[1] 0.05113433 0.04826915\n\n\n\nCall:\nglm(formula = y ~ x, family = poisson)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.36644    0.05113  26.723   &lt;2e-16 ***\nx           -0.02862    0.04827  -0.593    0.553    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 93.889  on 99  degrees of freedom\nResidual deviance: 93.538  on 98  degrees of freedom\nAIC: 408.25\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\nModify your newton_poisson() function to return a 95% confidence interval for \\(\\beta\\). How do your results compare to glm()?\n\n\nfunction (x, y = NULL, na.rm = FALSE, use) \n{\n    if (missing(use)) \n        use &lt;- if (na.rm) \n            \"na.or.complete\"\n        else \"everything\"\n    na.method &lt;- pmatch(use, c(\"all.obs\", \"complete.obs\", \"pairwise.complete.obs\", \n        \"everything\", \"na.or.complete\"))\n    if (is.na(na.method)) \n        stop(\"invalid 'use' argument\")\n    if (is.data.frame(x)) \n        x &lt;- as.matrix(x)\n    else if (!is.null(x)) \n        stopifnot(is.atomic(x))\n    if (is.data.frame(y)) \n        y &lt;- as.matrix(y)\n    else if (!is.null(y)) \n        stopifnot(is.atomic(y))\n    .Call(C_cov, x, y, na.method, FALSE)\n}\n&lt;bytecode: 0x10ef753a8&gt;\n&lt;environment: namespace:stats&gt;\n\n\n\n\n\n\nThis is the beginning of HW 2.\nFor a given subject in a study, we are interested in modeling \\(\\pi_i = P(Y_i = 1|X_i = x_i)\\), where \\(Y_i \\in \\{0, 1\\}\\). The logistic regression model takes the form\n\n\\[\\text{logit}(\\pi_i) = \\log \\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = \\log\\left({\\frac{P(Y_i = 1|X_i)}{1-P(Y_i = 1|X_i)}}\\right) = \\beta_0 + \\beta_1X_{1i} + \\beta_2X_{2i} + \\ldots + \\beta_pX_{pi}\\]\n\n\\(Y_1, Y_2,\\ldots, Y_n \\sim Bernoulli(\\pi)\\)\nPDF is \\(f(y_i; \\pi) = \\pi^{y_i}(1-\\pi)^{1-y_i}\\)\n\n\n\n\nDerive likelihood, gradient, and Hessian for logistic regression for an arbitrary number of predictors \\(p\\)\nWhat is the Newton’s method update for \\(\\beta\\) for logistic regression?\nIs logistic regression a convex optimization problem? Why or why not?"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html",
    "href": "slides/topic_optimization/s_MM.html",
    "title": "The EM algorithm II: theory and inference",
    "section": "",
    "text": "Today, we cover:\n\nThe MM Algorithm\n\nAnnouncements\n\nHW3 posted and due 3/4 at 10:00AM\n\nReadings:\n\nHunter and Lange: A tutorial on MM algorithms, The American Statistician\n\n\nTutorial article is very concise but overall pretty good if you want to learn more."
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#overview",
    "href": "slides/topic_optimization/s_MM.html#overview",
    "title": "The EM algorithm II: theory and inference",
    "section": "",
    "text": "Today, we cover:\n\nThe MM Algorithm\n\nAnnouncements\n\nHW3 posted and due 3/4 at 10:00AM\n\nReadings:\n\nHunter and Lange: A tutorial on MM algorithms, The American Statistician\n\n\nTutorial article is very concise but overall pretty good if you want to learn more."
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#em-as-mm",
    "href": "slides/topic_optimization/s_MM.html#em-as-mm",
    "title": "The EM algorithm II: theory and inference",
    "section": "EM as MM",
    "text": "EM as MM\nThe EM is a minorization approach. Instead of directly maximizing. the log-likelihood, which is hard, the algorithm constructs a minorizing function and optimizes that function instead.\nA function \\(g\\) minorizes \\(f\\) over \\(\\mathcal{X}\\) at \\(y\\) if:\n\n\\(g(x) \\le f(x) \\mbox{ for all } x \\in \\mathcal{X}\\)\n\\(g(y) = f(y)\\)"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#mm-algorithm",
    "href": "slides/topic_optimization/s_MM.html#mm-algorithm",
    "title": "The EM algorithm II: theory and inference",
    "section": "MM algorithm",
    "text": "MM algorithm\n\nStands for “Majorize-Minimization” or “Minorize-Maximization”, depending on whether the desired optimization is a minimization or a maximization\nNot actually an algorithm, but a strategy for constructing optimization algorithms\nEM is a special case"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#mm-algorithm-1",
    "href": "slides/topic_optimization/s_MM.html#mm-algorithm-1",
    "title": "The EM algorithm II: theory and inference",
    "section": "MM algorithm",
    "text": "MM algorithm\n\nStands for “Majorize-Minimization” or “Minorize-Maximization”,depending on whether the desired optimization is a minimization or a maximization\nNot actually an algorithm, but a strategy for constructing optimization algorithms\nEM is a special case\n\nIdea: MM algorithm operates by creating a surrogate function that minorizes or majorizes the objective function. When the surrogate function is optimized, the objective function is driven uphill or downhill as needed."
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#definition-of-an-mm-algorithm-for-minimization",
    "href": "slides/topic_optimization/s_MM.html#definition-of-an-mm-algorithm-for-minimization",
    "title": "The EM algorithm II: theory and inference",
    "section": "Definition of an MM algorithm for Minimization",
    "text": "Definition of an MM algorithm for Minimization\nWe first focus on the minimization problem, in which MM = Majorize–Minimize.\n\nA function \\(g(\\theta|\\theta^t)\\) is said to majorize the function \\(f(\\theta)\\) at \\(\\theta^t\\) if\n\n\\[\\begin{align}\nf(\\theta) &\\le g(\\theta|\\theta^t) \\mbox{ for all } \\theta\\\\[2mm]\nf(\\theta^t) &= g(\\theta^t|\\theta^t)\n\\end{align}\\]\n\nWe choose a majorizing function \\(g(\\theta|\\theta^t)\\) and minimize it, instead of minimizing \\(f(\\theta)\\). Denote \\(\\theta^{t+1} =\\arg\\min_{\\theta}g(\\theta|\\theta^t)\\). Iterate until \\(\\theta^t\\) converges.\nDescent property: \\(f(\\theta^t) \\le g(\\theta^{t+1}|\\theta^t)\\le g(\\theta^t|\\theta^t) = f(\\theta^t)\\)\n\n\nI think pictures really help here"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#definition-of-an-mm-algorithm-for-minimization-1",
    "href": "slides/topic_optimization/s_MM.html#definition-of-an-mm-algorithm-for-minimization-1",
    "title": "The EM algorithm II: theory and inference",
    "section": "Definition of an MM algorithm for Minimization",
    "text": "Definition of an MM algorithm for Minimization\n\n\n\n\n\n\n\n\n\n\nTwo examples: Dotted line here is the majorizing function"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#mm-algorithm-for-maximization",
    "href": "slides/topic_optimization/s_MM.html#mm-algorithm-for-maximization",
    "title": "The EM algorithm II: theory and inference",
    "section": "MM algorithm for Maximization",
    "text": "MM algorithm for Maximization\nIn a maximization problem, MM = Minorize–Maximize.\n\nTo maximize \\(f(\\theta)\\), we minorize it by a surrogate function \\(g(\\theta|\\theta^t)\\) and maximize \\(g(\\theta|\\theta^t)\\) to produce the next iteration \\(\\theta^{t+1}\\)\n\\(g(\\theta|\\theta^t)\\) minorizes \\(f(\\theta)\\) at \\(\\theta^t\\) if \\(-g(\\theta|\\theta^t)\\) majorizes \\(-f(\\theta)\\)"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#separation-of-high-dimensional-parameter-spaces",
    "href": "slides/topic_optimization/s_MM.html#separation-of-high-dimensional-parameter-spaces",
    "title": "The EM algorithm II: theory and inference",
    "section": "Separation of high-dimensional parameter spaces",
    "text": "Separation of high-dimensional parameter spaces\nOne of the key criteria in judging majorizing or minorizing functions is their ease of optimization.\n\nSuccessful MM algorithms in high-dimensional parameter spaces often rely on surrogate functions in which the individual parameter components are separated, i.e., for \\(\\theta = (\\theta_1, \\ldots, \\theta_p)\\),\n\n\\[g(\\theta|\\theta^t) = \\sum_{j = 1}^p q_j(\\theta_j)\\] where \\(q_j(\\cdot)\\) are univariate functions.\nBecause the \\(p\\) univariate functions may be optimized one by one, this makes the surrogate function easier to optimize at each iteration."
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#advantages-of-the-mm-algorithm",
    "href": "slides/topic_optimization/s_MM.html#advantages-of-the-mm-algorithm",
    "title": "The EM algorithm II: theory and inference",
    "section": "Advantages of the MM algorithm",
    "text": "Advantages of the MM algorithm\n\nNumerical stability: warranted by the descent (or ascent) property\nSimplicity: Turn a difficult optimization problem into a simple one\n\nIt can turn a non-differentiable problem into a smooth problem (Example 2).\nIt can separate the parameters of a problem (Example 3).\nIt can linearize an optimization problem (Example 3).\nIt can deal gracefully with equality and inequality constraints (Example 4).\nIt can generate an algorithm that avoids large matrix inversion (5).\n\nIteration is the price we pay for simplifying the original problem.\n\n\nSeems like magic. How do you actually construct the surrogate function?"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#em-algorithm-vs.-mm-algorithm",
    "href": "slides/topic_optimization/s_MM.html#em-algorithm-vs.-mm-algorithm",
    "title": "The EM algorithm II: theory and inference",
    "section": "EM algorithm vs. MM algorithm",
    "text": "EM algorithm vs. MM algorithm\n\nEM: The E-step creates a surrogate function by identifying a complete-data log-likelihood function and evaluating it with respect to the observed data. The M-step maximizes the surrogate function. Every EM algorithm is an example of an MM algorithm.\nEM: demands creativity in identifying the missing data (complete data) and technical skill in calculating an often complicated conditional expectation and then maximizing it analytically.\nMM: requires creativity in identifying the surrogate function, using proper inequalities."
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#inequalities-to-construct-majorizingminorizing-function",
    "href": "slides/topic_optimization/s_MM.html#inequalities-to-construct-majorizingminorizing-function",
    "title": "The EM algorithm II: theory and inference",
    "section": "Inequalities to construct majorizing/minorizing function",
    "text": "Inequalities to construct majorizing/minorizing function\n\nProperty of convex function: A function \\(f: R^p \\to R\\) is \\(\\textbf{convex}\\) if for all \\(x_1, x_2 \\in R^p\\) and all \\(\\alpha \\in [0,1]\\), \\[\nf(\\alpha x_1 + (1-\\alpha)x_2)\\leq \\alpha f(x_1) + (1-\\alpha) f(x_2)\n\\]\nJensen’s inequality: for any convex function \\(f\\) and r.v. \\(x\\),\n\n\\[f[E(x)] \\le E[f(x)]\\]\n\nSupporting hyperplanes: If \\(f\\) is convex and differentiable, then\n\n\\[f(y)\\geq f(x)+\\nabla f(x)^\\top(y-x), \\forall x,y\\in\\mathbb{R}^p,\\]\nand equality holds when \\(y = x\\).\n\n\nFor concave function, jensen’s inequality reverses\nDraw supporting hyperplane from slide 7 of Hao MM lecture"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#inequalities-continued",
    "href": "slides/topic_optimization/s_MM.html#inequalities-continued",
    "title": "The EM algorithm II: theory and inference",
    "section": "Inequalities (continued)",
    "text": "Inequalities (continued)\n\nArithmetic-Geometric Mean Inequality: For nonnegative \\(x_1,\\ldots, x_m,\\) \\[\\sqrt[m]{\\prod_i^mx_i}\\le \\frac{1}{m}\\sum_{i=1}^mx_i,\\] and the equality holds iff \\(x_1 = x_2 = \\ldots = x_m\\).\nCauchy-Schwartz Inequality: for \\(p\\)-vectors \\(x\\) and \\(y\\),\n\n\\[x^Ty\\le ||x||\\cdot ||y||,\\]\nwhere \\(||x|| = \\sqrt{\\sum_i^p x_i^2}\\) is the norm of the vector.\n\nCheck that this definition of Cauchy-Schwartz is correct. Shouldn’t this be called the L2 norm? Or is it any norm?"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#inequalities-continued-1",
    "href": "slides/topic_optimization/s_MM.html#inequalities-continued-1",
    "title": "The EM algorithm II: theory and inference",
    "section": "Inequalities (continued)",
    "text": "Inequalities (continued)\n\nQuadratic upper bound: If a convex function \\(f(x)\\) is twice differentiable and has bounded curvature, then we can majorize \\(f(x)\\) by a quadratic function with sufficiently high curvature and tangent to \\(f(x)\\) at \\(x^t\\). In algebraic terms, we can find a positive definite matrix \\(M\\) such that \\(M-\\nabla^2f(x)\\) is nonnegative for all \\(x\\), then\n\n\\[f(x)\\le f(x^t) + \\nabla f(x^t)^T(x-x^t) + \\frac{1}{2}(x-x^t)^TM(x-x^t)\\] provides a quadratic upper bound that majorizes \\(f(x)\\).\n\nHow do you check if it has bounded curvature?"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#example-1-em-algorithms",
    "href": "slides/topic_optimization/s_MM.html#example-1-em-algorithms",
    "title": "The EM algorithm II: theory and inference",
    "section": "Example 1: EM algorithms",
    "text": "Example 1: EM algorithms\n\nBy Jensen’s inequality and the convexity of the function \\(-\\log(y)\\), we have for probability densities \\(a(y)\\) and \\(b(y)\\) that\n\n\\[-\\log \\left\\{E\\left[\\frac{a(y)}{b(y)}\\right]\\right\\} \\le E\\left[ -\\log\\frac{a(y)}{b(y)} \\right]\\]\n\n\\(Y\\) has the density \\(b(y)\\), then \\(E[a(y)/b(y)] = 1\\). The left hand side vanishes, and we obtain \\[E[\\log a(y)] \\le E[\\log b(y)],\\]\n\nthe Kullback-Leibler divergence.\n\nThis inequality guarantees that a minorizing function is constructed in the E-step of any EM algorithm, making every EM algorithm an MM algorithm.\n\n\nI’m glossing over a lot of details here but this is basically shorthand for another proof of EM that uses Jensen’s inequality"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#example-1-em-algorithms-cont",
    "href": "slides/topic_optimization/s_MM.html#example-1-em-algorithms-cont",
    "title": "The EM algorithm II: theory and inference",
    "section": "Example 1: EM algorithms, cont",
    "text": "Example 1: EM algorithms, cont\n\nWe have the decomposition\n\n\\[\\begin{align}\nQ(\\theta|\\theta^t) &= E_z\\left[\\log p(y, z |\\theta)|y, \\theta^t\\right]\\\\[2mm]\n&= E\\left[\\log p(z|y,\\theta)|y, \\theta^t\\right] + \\log p(y|\\theta)\n\\end{align}\\]\nBY KL divergence,\n\\[E\\left[\\log p(z|y,\\theta)|y, \\theta^t\\right] \\le E\\left[\\log p(z|y,\\theta^t)|y, \\theta^t\\right] \\forall \\theta\\]\nWe obtain the surrogate function that minorizes the objective function\n\\[ \\log p(y|\\theta) \\ge Q(\\theta|\\theta^t) -  E\\left[\\log p(z|y,\\theta^t)|y, \\theta^t\\right]\\]"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#example-2-finding-a-sample-median",
    "href": "slides/topic_optimization/s_MM.html#example-2-finding-a-sample-median",
    "title": "The EM algorithm II: theory and inference",
    "section": "Example 2: finding a sample median",
    "text": "Example 2: finding a sample median\n\nConsider the sequence of numbers \\(y_1, \\ldots y_n\\). The sample median \\(\\theta\\) minimizes the non-differentiable objective function\n\n\\[f(\\theta) = \\sum_i^n |y_i-\\theta|.\\]\n\nThe quadratic function\n\n\\[h_i(\\theta|\\theta^t) = \\frac{(y_i-\\theta)^2}{2|y_i-\\theta^t|}+\\frac 1 2 |y_i-\\theta^t|\\] majorizes \\(|y_i-\\theta|\\) at the point \\(\\theta^t\\) (Arithmetic-Geometric Mean Inequality).\n\nHence, \\(g(\\theta|\\theta^t) = \\sum_i^n h_i(\\theta|\\theta^t)\\) majorizes \\(f(\\theta)\\).\n\n\nCan we draw a picture of this to make it more obvious?"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#example-2-finding-a-sample-median-continued",
    "href": "slides/topic_optimization/s_MM.html#example-2-finding-a-sample-median-continued",
    "title": "The EM algorithm II: theory and inference",
    "section": "Example 2: finding a sample median (continued)",
    "text": "Example 2: finding a sample median (continued)\nWe have the following objective function (a weighted sum of squares):\n\\[g(\\theta|\\theta^t) = \\frac{1}{2}\\sum_i^n\\left[\\frac{(y_i-\\theta)^2}{|y_i-\\theta^t|}+|y_i-\\theta^t|\\right]\\] - The minimum of \\(g(\\theta|\\theta^t)\\) occurs at\n\\[\\theta^{t+1} = \\frac{\\sum_i^nw_i^ty_i}{w^t_i}, w_i^t = |y_i-\\theta^t|^{-1}\\] - This algorithm works except when a weight \\(w_i^t=\\infty\\). It generalizes to sample quantiles, LASSO, and quantile regression.\n\nMight be good to think through how to generalize this to a non-median quantile"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#example-2-finding-a-sample-median-continued-1",
    "href": "slides/topic_optimization/s_MM.html#example-2-finding-a-sample-median-continued-1",
    "title": "The EM algorithm II: theory and inference",
    "section": "Example 2: finding a sample median (continued)",
    "text": "Example 2: finding a sample median (continued)\nDo lab exercise 1"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#finding-a-sample-quantile",
    "href": "slides/topic_optimization/s_MM.html#finding-a-sample-quantile",
    "title": "The EM algorithm II: theory and inference",
    "section": "Finding a sample quantile",
    "text": "Finding a sample quantile\nMedian example generalizes to finding a sample quantile. A \\(q\\)th sample quantile of \\(y_1,\\ldots, y_n\\) is one that minimizes the function\n\\[f(\\theta) = \\sum_i p_q(y_i-\\theta)\\]\nWhere \\(p_q(\\theta) = q\\theta\\) if \\(\\theta \\ge 0\\) and \\(p_q(\\theta) = -q(1-\\theta)\\) if \\(\\theta &lt; 0\\). A majorizing function is\n\\[g_q(\\theta|\\theta^t) = \\frac{1}{4}\\sum_i^n\\left[\\frac{(y_i-\\theta)^2}{|y_i-\\theta^t|}+ (4q-2)(y_i-\\theta)+ |y_i-\\theta^t|\\right]\\]"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#finding-a-sample-quantile-1",
    "href": "slides/topic_optimization/s_MM.html#finding-a-sample-quantile-1",
    "title": "The EM algorithm II: theory and inference",
    "section": "Finding a sample quantile",
    "text": "Finding a sample quantile"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#example-3-bradley-terry-ranking",
    "href": "slides/topic_optimization/s_MM.html#example-3-bradley-terry-ranking",
    "title": "The EM algorithm II: theory and inference",
    "section": "Example 3: Bradley-Terry Ranking",
    "text": "Example 3: Bradley-Terry Ranking\nConsider a sports league with \\(n\\) teams. Assign team \\(i\\) the skill level \\(\\theta_i\\), where \\(\\theta_1 = 1\\) for identifiability. Bradley and Terry proposed the model\n\\[Pr(i \\mbox{ beats } j) = \\frac{\\theta_i}{\\theta_i + \\theta_j}.\\]\n\nIf \\(b_{ij}\\) is the number of times \\(i\\) beats \\(j\\), then the likelihood of the data is\n\n\\[L(\\theta) = \\prod_{i\\ne j}\\left(\\frac{\\theta_i}{\\theta_i + \\theta_j}\\right)^{b_{ij}}.\\] We estimate \\(\\theta\\) by maximizing \\(f(\\theta) = \\log L(\\theta)\\) and then rank the teams on the basis of the estimates."
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#example-3-bradley-terry-ranking-1",
    "href": "slides/topic_optimization/s_MM.html#example-3-bradley-terry-ranking-1",
    "title": "The EM algorithm II: theory and inference",
    "section": "Example 3: Bradley-Terry Ranking",
    "text": "Example 3: Bradley-Terry Ranking\n\nThe log-likelihood is \\(f(\\theta) = \\sum_{i \\ne j}b_{ij}[\\log\\theta_i - \\log(\\theta_i + \\theta_j)]\\).\nWe need to linearize the term \\(-\\log(\\theta_i + \\theta_j)\\) to separate parameters.\n\n\nThis whole lecture is more about neat things you should come back to if you need more rather than stuff to build on or try yourself, necessarily"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#example-3-bradley-terry-ranking-continued",
    "href": "slides/topic_optimization/s_MM.html#example-3-bradley-terry-ranking-continued",
    "title": "The EM algorithm II: theory and inference",
    "section": "Example 3: Bradley-Terry Ranking (continued)",
    "text": "Example 3: Bradley-Terry Ranking (continued)\n\nBy the supporting hyperplane property when \\(f\\) is convex and the convecity of \\(-\\log(\\cdot)\\), we have\n\n\\[-\\log(y)\\ge -\\log(x) - x^{-1}(y-x) = -\\log(x) - y/x+ 1\\]\n\nThe inequality indicates that\n\n\\[-\\log(\\theta_i+\\theta_j) \\ge -\\log(\\theta_i^t+\\theta_j^t) - \\frac{\\theta_i+\\theta_j}{\\theta_i^t+\\theta_j^t}+ 1\\]"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#example-3-bradley-terry-ranking-continued-1",
    "href": "slides/topic_optimization/s_MM.html#example-3-bradley-terry-ranking-continued-1",
    "title": "The EM algorithm II: theory and inference",
    "section": "Example 3: Bradley-Terry Ranking (continued)",
    "text": "Example 3: Bradley-Terry Ranking (continued)\n\nThus, the minorizing function is\n\n\\[g(\\theta|\\theta^t) = \\sum_{i\\ne j}b_{ij}\\left[ \\log\\theta_i -\\log(\\theta_i^t +\\theta_j^t) - \\frac{\\theta_i + \\theta_j}{\\theta_i^t+\\theta_j^t} + 1\\right].\\]\n\nThe parameters are now separated. We can easily find the optimal point\n\n\\[\\theta_i^t = \\frac{\\sum_{i\\ne j}b_{ij}}{\\sum_{i\\ne j}(b_{ij}+b_{ji})/(\\theta_i^t + \\theta_j^t)}\\]"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#bt-ranking",
    "href": "slides/topic_optimization/s_MM.html#bt-ranking",
    "title": "The EM algorithm II: theory and inference",
    "section": "BT Ranking",
    "text": "BT Ranking\nLab exercise 2"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#example-4-handling-constraints",
    "href": "slides/topic_optimization/s_MM.html#example-4-handling-constraints",
    "title": "The EM algorithm II: theory and inference",
    "section": "Example 4: Handling constraints",
    "text": "Example 4: Handling constraints\n\nConsider the problem of minimizing \\(f(\\theta)\\) subject to the constraints \\(v_j(\\theta)\\ge 0\\) for \\(1\\le j\\le q\\), where each \\(v_j(\\theta)\\) is a concave, differentiable function.\nBy the supporting hyperplane property and the convexity of \\(-v_j(\\theta)\\),\n\n\\[v_j(\\theta^t) - v_j(\\theta) \\ge -[\\nabla v_j(\\theta^t)]^T(\\theta-\\theta^t) \\tag{2}.\\]\n\nAgain, by the supporting hyperplane property and the convexity of \\(-\\log(\\cdot)\\), we have \\(-\\log y + log x \\ge -x^{-1}(y-x) \\implies x(-\\log y + \\log x) \\ge x-y\\). Then:\n\n\\[\\begin{equation}\nv_j(\\theta^t)[-\\log v_j(\\theta)+\\log v_j(\\theta^t)]\\ge v_j(\\theta^t)-v_j(\\theta).\n\\end{equation}\\tag{3}\\]"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#example-4-handling-constraints-1",
    "href": "slides/topic_optimization/s_MM.html#example-4-handling-constraints-1",
    "title": "The EM algorithm II: theory and inference",
    "section": "Example 4: Handling constraints",
    "text": "Example 4: Handling constraints\nBy (2) and (3) on the previous slide,\n\\[v_j(\\theta^t)[-\\log v_j(\\theta)+\\log v_j(\\theta^t)] + [\\nabla v_j(\\theta^t)]^T(\\theta-\\theta^t) \\ge 0\\]\nand the equality holds when \\(\\theta = \\theta^t\\).\n\nSumming over \\(j\\) and multiplying by a positive tuning parameter \\(\\omega\\), we construct the surrogate function that majorizes \\(f(\\theta)\\),\n\n\\[g(\\theta|\\theta^t) = f(\\theta) + \\omega \\sum_{j = 1}^q \\left[v_j(\\theta^t)\\log\\frac{v_j(\\theta^t)}{v_j(\\theta)} + [\\nabla v_j(\\theta^t)]^T(\\theta-\\theta^t) \\right] \\ge f(\\theta)\\]"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#handling-constraints-continued",
    "href": "slides/topic_optimization/s_MM.html#handling-constraints-continued",
    "title": "The EM algorithm II: theory and inference",
    "section": "Handling constraints (continued)",
    "text": "Handling constraints (continued)\n\nNote:\n\nMajorization gets rid of the inequality constraints!\nThe presence of \\(\\log v_j(\\theta)\\) ensures \\(v_j(\\theta)\\ge 0\\)\n\nAn initial point \\(\\theta^0\\) must be selected with all inequality constraints strictly satisfied. All iterates stay within the interior region but allows strict inequalities to become equalities at the limit\nThe minimization step of the MM algorithm can be carried out approximately by Newton’s method.\nWhere there are linear equality constraints \\(A\\theta = b\\) in addition to the inequality constraints \\(v_j(\\theta)\\ge 0\\), these should be enforced by introducing Lagrange multipliers during the minimization of \\(g(\\theta|\\theta^t)\\).\n\n\nWe will talk more about constrained optimization and consider different approaches in a later lecture"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#comparing-mm-and-newtons-method",
    "href": "slides/topic_optimization/s_MM.html#comparing-mm-and-newtons-method",
    "title": "The EM algorithm II: theory and inference",
    "section": "Comparing MM and Newton’s Method",
    "text": "Comparing MM and Newton’s Method\n\nConvergence rate\n\nN: a quadratic rate \\(\\lim ||\\theta^{t+1}-\\hat{\\theta}||/||\\theta^{t+1}-\\hat{\\theta}||^2 = c\\)\nMM: a linear rate \\(\\lim ||\\theta^{t+1}-\\hat{\\theta}||/||\\theta^{t+1}-\\hat{\\theta}|| = c &lt; 1\\)\n\nComplexity of each iteration\n\nN: requires evaluation and inversion of Hessian, \\(O(p^3)\\)\nMM: separates parameters, \\(O(p)\\) or \\(O(p^2)\\)\n\nStability of the algorithm\n\nN: behaves poorly if started too far from an optimum point\nMM: guaranteed to increase/decrease the objective function at every iteration"
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#comparing-mm-and-newtons-method-1",
    "href": "slides/topic_optimization/s_MM.html#comparing-mm-and-newtons-method-1",
    "title": "The EM algorithm II: theory and inference",
    "section": "Comparing MM and Newton’s Method",
    "text": "Comparing MM and Newton’s Method\nIn conclusion, well-designed MM algorithms tend to require more iterations but simpler iterations than Newton’s method; thus MM sometimes enjoy an advantage in computation speed and numerical stability."
  },
  {
    "objectID": "slides/topic_optimization/s_MM.html#resources",
    "href": "slides/topic_optimization/s_MM.html#resources",
    "title": "The EM algorithm II: theory and inference",
    "section": "Resources",
    "text": "Resources\n\nKenneth Lange lecture\nExample with NMF\nLange examples of MM\n\n–"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html",
    "href": "slides/topic_optimization/s_gradient_methods.html",
    "title": "Gradient Methods",
    "section": "",
    "text": "Today, we cover:\n\nReview of GLMs\nGradient methods\n\nNewtons method continued\nIteratively reweighted least squares for GLM\nQuasi-Newton\n\n\nAnnouncements\n\nHW3 posted later today and due 3/4 at 10:00AM\nNo class tomorrow, 2/12\n\nReadings:\n\nPeng Chapter 3\nGivens and Hoeting Chapter 2"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#overview",
    "href": "slides/topic_optimization/s_gradient_methods.html#overview",
    "title": "Gradient Methods",
    "section": "",
    "text": "Today, we cover:\n\nReview of GLMs\nGradient methods\n\nNewtons method continued\nIteratively reweighted least squares for GLM\nQuasi-Newton\n\n\nAnnouncements\n\nHW3 posted later today and due 3/4 at 10:00AM\nNo class tomorrow, 2/12\n\nReadings:\n\nPeng Chapter 3\nGivens and Hoeting Chapter 2"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#rates-of-convergence",
    "href": "slides/topic_optimization/s_gradient_methods.html#rates-of-convergence",
    "title": "Gradient Methods",
    "section": "Rates of convergence",
    "text": "Rates of convergence\nOne of the ways algorithms can be compared is via their rates of convergence to some limiting value.\n\nTypically we have an iterative algorithm that is trying to find the max/min of an objective function \\(f\\)\n\nWant to estimate how long it will take to reach that optimal value\n\nThree rates of convergence we will focus on:\n\nlinear (slowest)\nsuperlinear (faster)\nquadratic (fastest)\n\n\nAlgorithms that require more information about \\(f\\) (such as its derivative) tend to converge more quickly.\n\nFaster rate here means fewer iterations, not necessarily faster computation time.\n\nimportant caveat is that these describe local convergence i.e. what happens when you’re already near the solution\ncost per iteration matters and sometimes cost is larger per iteration for quadratic methods"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#rates-of-convergence-1",
    "href": "slides/topic_optimization/s_gradient_methods.html#rates-of-convergence-1",
    "title": "Gradient Methods",
    "section": "Rates of convergence",
    "text": "Rates of convergence"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#generalized-linear-models-glms",
    "href": "slides/topic_optimization/s_gradient_methods.html#generalized-linear-models-glms",
    "title": "Gradient Methods",
    "section": "Generalized linear models (GLMs)",
    "text": "Generalized linear models (GLMs)\nExtension of standard linear model to allow for non-Normal response distributions.\n\\[\\begin{align}\ng(\\mu_i) &= x_i^T\\beta\\\\[3mm]\n\\mu_i &= E(Y_i|x_i)\n\\end{align}\\]\n\n\\(g(\\cdot)\\) is a known link function\n\\(Y_i \\sim EF\\), iid\n\nExponential Family distribution, i.e. Normal, binomial, Poisson, etc.\n\n\\(Var(Y_i|X_i) = \\phi Var(\\mu)\\)\n\nKnown variance function that (often) depends on the mean\n\n\n\nSometimes \\(g(\\mu_i) = \\eta_i\\) is called the linear predictor Link function links the linear predictor (linear combination of the covariates) with the mean of the outcome Linearity assumption now applies to \\(g(\\mu_i)\\)"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#canonical-links",
    "href": "slides/topic_optimization/s_gradient_methods.html#canonical-links",
    "title": "Gradient Methods",
    "section": "Canonical links",
    "text": "Canonical links"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#generalized-linear-models-glms-1",
    "href": "slides/topic_optimization/s_gradient_methods.html#generalized-linear-models-glms-1",
    "title": "Gradient Methods",
    "section": "Generalized linear models (GLMs)",
    "text": "Generalized linear models (GLMs)\nLinear regression:\n\\[\\hat{\\beta} = (X^TX)^{-1}X^TY\\]\nGLMs:\n\n\\(\\hat{\\beta}\\) (typically) cannot be obtained in closed form\nNeed an numeric estimation approach, i.e. an iterative algorithm"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#poisson-regression",
    "href": "slides/topic_optimization/s_gradient_methods.html#poisson-regression",
    "title": "Gradient Methods",
    "section": "Poisson regression",
    "text": "Poisson regression\n\\[\\log(E[Y_i|X_i]) = X_i^T\\beta \\]\n\n\\(Y_i \\sim Poisson(\\mu_i)\\)\n\\(Var(\\mu_i) = \\mu_i\\)\n\\(g'(\\mu_i) = \\frac{1}{\\mu_i}\\)\n\n How do we find \\(\\beta\\)?\n\nUse maximum likelihood"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#poisson-regression-log-likelihood",
    "href": "slides/topic_optimization/s_gradient_methods.html#poisson-regression-log-likelihood",
    "title": "Gradient Methods",
    "section": "Poisson regression log-likelihood",
    "text": "Poisson regression log-likelihood\n\\[l(\\mu_i) = \\sum_i \\left( y_i\\log\\mu_i-\\mu_i-\\log y_i!\\right)\\]\n\n\\(\\mu_i = e^{X_i^T\\beta}\\)\n\n\\[l(\\beta) = \\sum_i \\left( y_iX_i^T\\beta-e^{X_i^T\\beta}-\\log y_i!\\right)\\]\nEstimate unknown \\(\\beta\\) by solving\n\\[\\hat{\\beta} = \\arg\\min_{\\beta} \\sum_i \\left( y_iX_i^T\\beta-e^{X_i^T\\beta}-\\log y_i!\\right)\\]\n\nWrite this out in both latex and Yes,you can check second derivative"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#poisson-regression-log-likelihood-1",
    "href": "slides/topic_optimization/s_gradient_methods.html#poisson-regression-log-likelihood-1",
    "title": "Gradient Methods",
    "section": "Poisson regression log-likelihood",
    "text": "Poisson regression log-likelihood\nCan solve using steepest descent or Newton\n\nNeed gradient and Hessian\n\n - gradient: \\(\\frac{\\partial l(\\beta)}{\\partial \\beta} = \\sum_i(Y_i - e^{X_i^T\\beta})X_i\\)\n - Hessian: \\(\\frac{\\partial^2 l(\\beta)}{\\partial \\beta^2} = -\\sum_i e^{X_i^T\\beta} X_i^TX_i\\)\n\nIs this a convex optimization problem?\n\n\nSomething of an abuse of notation here. Always make sure your dimensions line up! Check the dimensions on this and make sure they are good, if not mess around with the transpose"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#poisson-regression-optimization",
    "href": "slides/topic_optimization/s_gradient_methods.html#poisson-regression-optimization",
    "title": "Gradient Methods",
    "section": "Poisson regression optimization",
    "text": "Poisson regression optimization\nUsing Steepest Descent:\n\\[\\beta_{t+1} = \\beta_t - \\alpha \\frac{\\partial l(\\beta)}{\\partial \\beta}\\]\nUsing Newton’s Method\n\\[\\beta_{t+1} = \\beta_t -  \\left[\\frac{\\partial^2 l(\\beta)}{\\partial \\beta^2}\\right]^{-1} \\frac{\\partial l(\\beta)}{\\partial \\beta}\\]\n\nNext we will look at Fisher scoring and IRLS, other numerical methods for obtaining MLE in GLMs"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#exercise",
    "href": "slides/topic_optimization/s_gradient_methods.html#exercise",
    "title": "Gradient Methods",
    "section": "Exercise",
    "text": "Exercise\nGo to lab exercise, implement Newton’s method for Poisson regression. Compare with result from glm()\n\nHave them start with the lab solution from last week For homework 2, they will do the same thing for logistic regression"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#fishers-information",
    "href": "slides/topic_optimization/s_gradient_methods.html#fishers-information",
    "title": "Gradient Methods",
    "section": "Fisher’s information",
    "text": "Fisher’s information\nSometimes, gradient and Hessian (or related quantities) go by other names in the context of statistical modeling.\n\nScore function: first derivative of log-likelihood with respect to parameter vector \\(\\boldsymbol{\\beta}\\). This is the gradient.\n\n\\[U(\\boldsymbol{\\beta}) = \\nabla \\log L(\\boldsymbol{\\beta})\\]\n\nInformation (aka Fisher’s information): negative expected value of the Hessian.\n\n\\[I(\\boldsymbol{\\beta}) = Var[U(\\boldsymbol{\\beta})] = -E\\left[ \\nabla^2 \\log L(\\boldsymbol{\\beta})\\right] = [Var(\\beta)]^{-1}\\]\n\nobserved information: A function of the sample size \\(n\\)\n\n\\[I_n(\\boldsymbol{\\theta}) = - [\\nabla^2 \\log L(\\boldsymbol{\\theta})]_{\\theta = \\hat{\\theta}}\\]\n\nOften you will see different notation for the observed vs. expected information"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#observed-vs.-expected-information",
    "href": "slides/topic_optimization/s_gradient_methods.html#observed-vs.-expected-information",
    "title": "Gradient Methods",
    "section": "Observed vs. Expected information",
    "text": "Observed vs. Expected information\n\nObserved information is often easier to work with\nIn many GLMs, observed and expected information are equivalent\nExpected information shown to outperform observed in constructing confidence intervals"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#observed-vs.-expected-information-poisson",
    "href": "slides/topic_optimization/s_gradient_methods.html#observed-vs.-expected-information-poisson",
    "title": "Gradient Methods",
    "section": "Observed vs. Expected information: Poisson",
    "text": "Observed vs. Expected information: Poisson\n\nFor other GLMs with canonical link this is also true"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#newtons-method-for-glms",
    "href": "slides/topic_optimization/s_gradient_methods.html#newtons-method-for-glms",
    "title": "Gradient Methods",
    "section": "Newton’s method for GLMs",
    "text": "Newton’s method for GLMs\nFrom last lecture, the Newton’s method update is:\n\\[x_{t+1} = x_t - \\{ f''(x_t) \\}^{-1} f'(x_t).\\]\nIf you are trying to optimize parameters \\(\\beta\\) in a log-likelihood function, this becomes:\n\\[\\begin{align}\n\\beta_{t+1} &= \\beta_t - \\{ l''(\\beta_t) \\}^{-1} l'(\\beta_t)\\\\\n&= \\beta_t + \\{I_n(\\beta_t) \\}^{-1}U(\\beta_t)\n\\end{align}\\]\n Fisher Scoring \\[\\beta_{t+1}= \\beta_t + \\{I(\\beta_t) \\}^{-1}U(\\beta_t)\\]\n\nFor exponential family in canonical form, Newton’s method and fisher scoring are identical (prove this to yourself- is it for only one parameter? Does it apply for GLMs?)"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#fisher-scoring",
    "href": "slides/topic_optimization/s_gradient_methods.html#fisher-scoring",
    "title": "Gradient Methods",
    "section": "Fisher scoring",
    "text": "Fisher scoring\nSimilar to Newton’s method, but replace observed information for Expected information.\n\nNewton’s method and Fisher scoring have the same asympotic properties, but for individual problems one or another may be easier computationally or analytically\n\nI.E., for when observed information isn’t semi positive definite and can’t be inverted\n\nHowever, Newton’s method and Fisher scoring are equivalent for GLM with canonical link\n\nThis is because the observed and expected information are the same in this setting (check!)\n\n\n\\[\\beta_{t+1} = \\beta_t + \\{I(\\beta_t) \\}^{-1}U(\\beta_t)\\]\n\nReally, this is just a special case of gradient descent similar but less general than Newton."
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#iteratively-reweighted-least-squares-for-glm",
    "href": "slides/topic_optimization/s_gradient_methods.html#iteratively-reweighted-least-squares-for-glm",
    "title": "Gradient Methods",
    "section": "Iteratively reweighted least squares for GLM",
    "text": "Iteratively reweighted least squares for GLM\nIn GLM, there is usually no closed form solution for the MLE, so the model fitting is done numerically as we’ve seen. In linear regression models, \\(E(y_i |x_i)  = x_i^T \\beta\\), and we minimize\n\\[S(\\beta) = \\sum_i (y_i - x_i^T \\beta)^2, \\]\nto get \\(\\hat{\\beta} = (X^TX)^{-1}X^TY\\).\nQuestion: For GLMs, can we minimize \\(S(\\beta) = \\sum_i (g(y_i) - x_i^T \\beta)^2\\)? Answer: No, because \\(E(g(y|x))\\ne g(E(y|x)) = x^\\beta\\), since \\(g\\) is nonlinear. This means we cannot transform \\(y\\) by \\(g\\) and then run linear regression.\n\nWhy or why not? Idea is that it would be nice if we could do linear regression"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#iteratively-reweighted-least-squares",
    "href": "slides/topic_optimization/s_gradient_methods.html#iteratively-reweighted-least-squares",
    "title": "Gradient Methods",
    "section": "Iteratively reweighted least squares",
    "text": "Iteratively reweighted least squares\nIdea: Approximate \\(g(y_i)\\) by a linear function so that the OLS formula can be used.\n Algorithm: at step \\(t\\) with current solution \\(\\beta^t\\), linearize \\(g(y_i)\\) around \\(\\hat{\\mu}^t = g^{-1}(x_i^T\\beta^t)\\) (the fitted value for \\(y_i\\) at current step).\nDenote the linearized value by \\(\\tilde{y}_i^t\\)\n\\[\\tilde{y}_i^t = g(\\hat{\\mu}^t) + (y_i-\\hat{\\mu}^t)g'(\\hat{\\mu}^t ).\\]\nNow we can regress \\(\\tilde{y}_i^t\\) on \\(x_i\\) to estimate \\(\\beta^{t + 1}\\). However, \\(\\tilde{y}_i^t\\) is heteroscedastic, i.e., the variances are not identical. - For most distributions the variances is related to the mean.\n\nI don’t love this notation, but it seems to make sense"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#iteratively-reweighted-least-squares-1",
    "href": "slides/topic_optimization/s_gradient_methods.html#iteratively-reweighted-least-squares-1",
    "title": "Gradient Methods",
    "section": "Iteratively reweighted least squares",
    "text": "Iteratively reweighted least squares\nDerive the variances of \\(\\tilde{y}_i^t\\), and use the inverse of the variance as weights in a weighted least square (WLS):\n\\[W_i^t = \\left[Var(\\tilde{y}_i^t) \\right]^{-1} = \\left[ \\{g'(\\hat{\\mu}^t)\\}^2V(\\hat{\\mu}^t) \\right]^{-1}\\]\nWe can then minimize the following:\n\\[S(\\beta) = \\sum_i W_i^t(\\tilde{y}_i^t - x_i^T \\beta)^2. \\]\nWhich gives solution\n\\[\\hat{\\beta} = (X^TW^tX)^{-1}(X^TW^t \\tilde{y}^t)\\]"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#iteratively-reweighted-least-squares-2",
    "href": "slides/topic_optimization/s_gradient_methods.html#iteratively-reweighted-least-squares-2",
    "title": "Gradient Methods",
    "section": "Iteratively reweighted least squares",
    "text": "Iteratively reweighted least squares\nIRLS algorithm:\n\nStart with initial estimates, generally \\(\\mu_i^0 = y_i\\)\nForm \\(\\tilde{y}^t\\) and \\(W^t\\)\nEstimate \\(\\beta^{t+1}\\)\nForm \\(\\mu_i^{t+ 1}= g^{-1}(x_i^T\\beta^{t+1})\\), and return to step 2\n\n\nMcCullagh and Nelder (1983) showed that IRLS is equivalent to Fisher scoring.\nUsing the canonical link, IRLS is also equivalent to Newton-Raphson\n\n\nIRLS comes up in gams too, but we’re not going to cover that this eyar Newton is same as Newton-Raphson"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#inference-on-glm-parameter-estimates",
    "href": "slides/topic_optimization/s_gradient_methods.html#inference-on-glm-parameter-estimates",
    "title": "Gradient Methods",
    "section": "Inference on GLM parameter estimates",
    "text": "Inference on GLM parameter estimates\n\n\\(\\hat{Var}(\\hat{\\theta}) = [I(\\hat{\\theta})]^{-1}\\)\nThen can use LRT, Wald, or Score test to obtain \\(p\\)-values and confidence intervals\n\n Wald test statistic \\(Z\\) is given by \\[Z^2 = (\\hat{\\theta}_{MLE}- \\theta_{H_0})^T[I(\\hat{\\theta}_{MLE})](\\hat{\\theta}_{MLE}- \\theta_{H_0}) \\sim \\chi^2_{df}\\]\n\ndf is the number of parameters being estimated in \\(\\theta\\)\n\n\nUse information from the final iteration of your algorithm\nIf your algorithm doesn’t converge your inference won’t have asymptotic properties that hole Asymptotically equivalent to use observed or expected information,\nWald test showing multivariate version but the univariate version is the one we use all the time\nPlan to write out univariate version"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#quasi-newton",
    "href": "slides/topic_optimization/s_gradient_methods.html#quasi-newton",
    "title": "Gradient Methods",
    "section": "Quasi-Newton",
    "text": "Quasi-Newton\nQuasi-Newton methods use Newton-like updates while avoiding repeated Hessian at each step.\n\nMotivation:\n\nComputing \\(H\\) scales as \\(O(n^2)\\), inverting it scales as \\(O(n^3)\\)\nFor \\(50\\)-dimensional parameter, need to calculate \\(50(50+1)/2 = 1275\\) values for \\(H\\) at each step, then perform another \\(\\approx 50^3\\) operations to invert it.\n\n\n\\[x_{t+1} = x_t - \\{ f''(x_t) \\}^{-1} f'(x_t).\\]\nQuasi-Newton:\n\\[x_{t+1} = x_t - B_t^{-1} f'(x_t).\\]\nWhere \\(B_t\\) is simpler to compute.\n\nSteps of Newton can be slow when Hessian is large. Idea is to replace hessian with something easier to compute that still retains good convergence properties."
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#quasi-newton-1",
    "href": "slides/topic_optimization/s_gradient_methods.html#quasi-newton-1",
    "title": "Gradient Methods",
    "section": "Quasi-Newton",
    "text": "Quasi-Newton\nChallenging because \\(f''(x_t)\\) gives us a lot of information about the surface of \\(f\\) at \\(x_t\\) and throwing this out results in loss of information. Idea with Quasi-Newton is to find a solution \\(B_t\\) to the secant equation,\n\\[f'(x_t)-f'(x_{t-1}) = B_t(x_t-x_{t-1}).\\]\nIn one dimension, this is simple. In multiple dimensions there are infinite solutions and we need to constrain the problem:\n\n\\(B_t\\) should be symmetric\nShould be close to \\(B_{t-1}\\)\n\n\nshow what the solution is in one dimension symmetric because it approximates hessian\n\nessentially, we are replacing need to take second derivative with finite difference from previous iteration\nreplacing the second derivative with its finite difference approximation"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#quasi-newton-2",
    "href": "slides/topic_optimization/s_gradient_methods.html#quasi-newton-2",
    "title": "Gradient Methods",
    "section": "Quasi-Newton",
    "text": "Quasi-Newton\nLet \\(y_t = f'(x_t)-f'(x_{t-1})\\) and \\(s_t = x_t-x_{t-1}\\) such that \\(y_t = B_ts_t\\).\n Broyden, Fletcher, Goldfarb, and Shanno (BFGS) update:\n\\[B_t = B_{t-1} + \\frac{y_ty_t'}{y_t's_t} - \\frac{B_{t-1}s_ts'_tB'_{t-1}}{s'_tB_{t-1}s_t}\\]\n\nImplemented in optim() function in R\nInitialize \\(B_{t-1}^{-1}\\):\n\nset \\(B_{t-1}^{-1} = I\\)\ncompute and invert true Hessian at initial point\n\n\n\nTechnically, we use \\(B_t^{-1}\\) in the actual Newton equation. The Sherman-Morrison update formula allows us to generate the new inverse matrix without having to apply this and invert.\nI’m glossing over a lot of details here so that we can move on to other topics, but I have a nice blog post at the end of this lecture if you want to read more."
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#exercise-1",
    "href": "slides/topic_optimization/s_gradient_methods.html#exercise-1",
    "title": "Gradient Methods",
    "section": "Exercise",
    "text": "Exercise\nAdd inference to your Newton’s method for Poisson function. Compare with results from glm()."
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#homework-3",
    "href": "slides/topic_optimization/s_gradient_methods.html#homework-3",
    "title": "Gradient Methods",
    "section": "Homework 3",
    "text": "Homework 3\nLab Exercise 3: Begin to implement Newton’s method with inference for logistic regression (part 1 of Homework 3).\n\nFor homework 3, they will do the same thing for logistic regression"
  },
  {
    "objectID": "slides/topic_optimization/s_gradient_methods.html#resources",
    "href": "slides/topic_optimization/s_gradient_methods.html#resources",
    "title": "Gradient Methods",
    "section": "Resources",
    "text": "Resources\n\nGreat blog post on Quasi Newton"
  }
]